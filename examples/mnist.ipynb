{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    dict = np.load(file, allow_pickle=True)\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'MNIST/train.npy'\n",
    "test_file = 'MNIST/test.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(ai.Module):\n",
    "    def __init__(self):\n",
    "        self.conv1 = ai.Conv2d(1, 8, kernel_size=3, stride=1)\n",
    "        self.conv2 = ai.Conv2d(8, 16, kernel_size=3, stride=1)\n",
    "        self.fc1 = ai.Linear(2304, 128)\n",
    "        self.fc2 = ai.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        o1 = ai.G.relu(self.conv1.forward(x))\n",
    "        o2 = ai.G.relu(self.conv2.forward(o1))\n",
    "        o3 = ai.G.dropout(ai.G.maxpool2d(o2), p=0.75)\n",
    "        o4 = ai.G.dropout(ai.G.relu(self.fc1.forward(o3)), p=0.5)\n",
    "        o5 = self.fc2.forward(o4)\n",
    "        o6 = ai.G.softmax(o5)\n",
    "        return o6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST(\n",
      "  conv1: Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0), bias=True)\n",
      "  conv2: Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0), bias=True)\n",
      "  fc1: Linear(input_features=2304, output_features=128, bias=True)\n",
      "  fc2: Linear(input_features=128, output_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST()\n",
    "print(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = ai.Loss(loss_fn='CrossEntropyLoss')\n",
    "optim = ai.Optimizer(mnist.parameters(), optim_fn='Adadelta', lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = load_data(train_file)\n",
    "inputs = train_dict.item()['data']\n",
    "outputs = train_dict.item()['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "it, epoch = 0, 0\n",
    "loss = np.inf\n",
    "m = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    ai.G.grad_mode = False\n",
    "    file = test_file\n",
    "    dict = load_data(file)\n",
    "    inputs = dict.item()['data']\n",
    "    outputs = dict.item()['labels']\n",
    "    correct, total = 0, 0\n",
    "    test_m = m\n",
    "    for batch in range(int(len(outputs) / m)):\n",
    "        input = inputs[batch * test_m : (batch + 1) * test_m].reshape(test_m, 1, 28, 28) / 255\n",
    "        input =  np.stack([_ for _ in input], axis = -1)\n",
    "        output = np.array(outputs[batch * test_m : (batch + 1) * test_m])\n",
    "        scores = mnist.forward(input)\n",
    "        preds = np.argmax(scores.data, axis=0)\n",
    "        correct += np.sum(np.equal(output, preds))\n",
    "        total += test_m\n",
    "    accuracy = float(correct / total)\n",
    "    ai.G.grad_mode = True\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using Adadelta\n",
      "epoch: 1, iter: 0, loss: 2.3025889220413527\n",
      "epoch: 1, iter: 100, loss: 2.299660308329791\n",
      "epoch: 1, iter: 200, loss: 2.306180821471351\n",
      "epoch: 1, iter: 300, loss: 2.3213434113052767\n",
      "epoch: 1, iter: 400, loss: 2.3129695848127594\n",
      "epoch: 1, iter: 500, loss: 2.3319523321922553\n",
      "epoch: 1, iter: 600, loss: 2.301929027806004\n",
      "epoch: 1, iter: 700, loss: 2.33746649371023\n",
      "epoch: 1, iter: 800, loss: 2.3355563101670116\n",
      "epoch: 1, iter: 900, loss: 2.293141123555913\n",
      "epoch: 1, iter: 1000, loss: 2.3110276834634016\n",
      "epoch: 1, iter: 1100, loss: 2.2541160312853354\n",
      "epoch: 1, iter: 1200, loss: 2.3212566739882536\n",
      "epoch: 1, iter: 1300, loss: 2.306361155346287\n",
      "epoch: 1, iter: 1400, loss: 2.2610592577530726\n",
      "epoch: 1, iter: 1500, loss: 2.2992121039228035\n",
      "epoch: 1, iter: 1600, loss: 2.3184077971560346\n",
      "epoch: 1, iter: 1700, loss: 2.3007350787573664\n",
      "epoch: 1, iter: 1800, loss: 2.3135613867358797\n",
      "epoch: 1, iter: 1900, loss: 2.3124007018661135\n",
      "epoch: 1, iter: 2000, loss: 2.311620675471689\n",
      "epoch: 1, iter: 2100, loss: 2.3086767170776383\n",
      "epoch: 1, iter: 2200, loss: 2.2966798123500416\n",
      "epoch: 1, iter: 2300, loss: 2.275880875779502\n",
      "epoch: 1, iter: 2400, loss: 2.325083886067605\n",
      "epoch: 1, iter: 2500, loss: 2.330961395242505\n",
      "epoch: 1, iter: 2600, loss: 2.2901361518160286\n",
      "epoch: 1, iter: 2700, loss: 2.2896654717169915\n",
      "epoch: 1, iter: 2800, loss: 2.3025060497547347\n",
      "epoch: 1, iter: 2900, loss: 2.2899834634034404\n",
      "epoch: 1, iter: 3000, loss: 2.341872135611675\n",
      "epoch: 1, iter: 3100, loss: 2.294208221832415\n",
      "epoch: 1, iter: 3200, loss: 2.277887972288137\n",
      "epoch: 1, iter: 3300, loss: 2.2907692415339964\n",
      "epoch: 1, iter: 3400, loss: 2.2444543684152243\n",
      "epoch: 1, iter: 3500, loss: 2.298172340419691\n",
      "epoch: 1, iter: 3600, loss: 2.2965538234157776\n",
      "epoch: 1, iter: 3700, loss: 2.309702912452112\n",
      "epoch: 1, iter: 3800, loss: 2.3355428833681473\n",
      "epoch: 1, iter: 3900, loss: 2.3027710534304067\n",
      "epoch: 1, iter: 4000, loss: 2.301901307131142\n",
      "epoch: 1, iter: 4100, loss: 2.3088985597887843\n",
      "epoch: 1, iter: 4200, loss: 2.3060451691139456\n",
      "epoch: 1, iter: 4300, loss: 2.2855877964554887\n",
      "epoch: 1, iter: 4400, loss: 2.3353504653577577\n",
      "epoch: 1, iter: 4500, loss: 2.289113824317739\n",
      "epoch: 1, iter: 4600, loss: 2.310972146047935\n",
      "epoch: 1, iter: 4700, loss: 2.300022685718445\n"
     ]
    }
   ],
   "source": [
    "while epoch < 10:\n",
    "    epoch += 1\n",
    "    it = 0\n",
    "    for batch in range(int(len(outputs) / m)):\n",
    "    # for batch in range(1):\n",
    "        input = inputs[batch * m : (batch + 1) * m].reshape(m, 1, 28, 28) / 255\n",
    "        input =  np.stack([_ for _ in input], axis = -1)\n",
    "        output = outputs[batch * m : (batch + 1) * m]\n",
    "        onehot = np.zeros((10, m))\n",
    "        for _ in range(m):\n",
    "            onehot[output[_], _] = 1.0\n",
    "        scores = mnist.forward(input)\n",
    "        loss = L.loss(scores, onehot)\n",
    "        loss.backward()\n",
    "        optim.step()        # update parameters with optimization functions\n",
    "        optim.zero_grad()   # clearing the backprop list and resetting the gradients to zero\n",
    "        if it%100 == 0:\n",
    "            print('epoch: {}, iter: {}, loss: {}'.format(epoch, it, loss.data[0, 0]))\n",
    "        it += 1\n",
    "    print('\\n\\n', 'Epoch {} completed. Accuracy: {}'.format(epoch, evaluate()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
