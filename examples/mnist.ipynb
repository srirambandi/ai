{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/ai/blob/master/examples/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9wN37im_Tfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8r53PDe_KrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9bmOHys_KrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file):\n",
        "    dict = np.load(file, allow_pickle=True)\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWAbbmR__KrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = 'MNIST/train.npy'\n",
        "test_file = 'MNIST/test.npy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXtX27Iu_aWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54Di43Ig_KrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNIST(ai.Module):\n",
        "    def __init__(self):\n",
        "        self.conv1 = ai.Conv2d(1, 8, kernel_size=3, stride=1)\n",
        "        self.conv2 = ai.Conv2d(8, 16, kernel_size=3, stride=1)\n",
        "        self.fc1 = ai.Linear(2304, 128)\n",
        "        self.fc2 = ai.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        o1 = ai.G.relu(self.conv1.forward(x))\n",
        "        o2 = ai.G.relu(self.conv2.forward(o1))\n",
        "        o3 = ai.G.dropout(ai.G.maxpool2d(o2), p=0.75)\n",
        "        o4 = ai.G.dropout(ai.G.relu(self.fc1.forward(o3)), p=0.5)\n",
        "        o5 = self.fc2.forward(o4)\n",
        "        o6 = ai.G.softmax(o5)\n",
        "        return o6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ-s6GKb_KrX",
        "colab_type": "code",
        "outputId": "5cb82be5-8207-4947-cf0f-91536c0e6d66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "mnist = MNIST()\n",
        "print(mnist)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST(\n",
            "  conv1: Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0), bias=True)\n",
            "  conv2: Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0), bias=True)\n",
            "  fc1: Linear(input_features=2304, output_features=128, bias=True)\n",
            "  fc2: Linear(input_features=128, output_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmbTmDIz_Krb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = ai.Loss(loss_fn='CrossEntropyLoss')\n",
        "optim = ai.Optimizer(mnist.parameters(), optim_fn='Adadelta', lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDcxEtCQ_Krf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dict = load_data(train_file)\n",
        "inputs = train_dict.item()['data']\n",
        "outputs = train_dict.item()['labels']\n",
        "del train_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-0RMP7i_Krp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbv0nlzy_Krs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate():\n",
        "    ai.G.grad_mode = False\n",
        "    file = test_file\n",
        "    dict = load_data(file)\n",
        "    inputs = dict.item()['data']\n",
        "    outputs = dict.item()['labels']\n",
        "    correct, total = 0, 0\n",
        "    test_m = m\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "        input = inputs[batch * test_m : (batch + 1) * test_m].reshape(test_m, 1, 28, 28) / 255\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = np.array(outputs[batch * test_m : (batch + 1) * test_m])\n",
        "        scores = mnist.forward(input)\n",
        "        preds = np.argmax(scores.data, axis=0)\n",
        "        correct += np.sum(np.equal(output, preds))\n",
        "        total += test_m\n",
        "    accuracy = float(correct / total)\n",
        "    ai.G.grad_mode = True\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZlvHNr3M_Krw",
        "colab_type": "code",
        "outputId": "d6edb7a1-7370-4556-c8ca-a82dc7c91fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while epoch < 15:\n",
        "    epoch += 1\n",
        "    it = 0\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "    # for batch in range(1):\n",
        "        input = inputs[batch * m : (batch + 1) * m].reshape(m, 1, 28, 28) / 255\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = outputs[batch * m : (batch + 1) * m]\n",
        "        onehot = np.zeros((10, m))\n",
        "        for _ in range(m):\n",
        "            onehot[output[_], _] = 1.0\n",
        "        scores = mnist.forward(input)\n",
        "        loss = L.loss(scores, onehot)\n",
        "        loss.backward()\n",
        "        optim.step()        # update parameters with optimization functions\n",
        "        optim.zero_grad()   # clearing the backprop list and resetting the gradients to zero\n",
        "        if it%50 == 0:\n",
        "            print('epoch: {}, iter: {}, loss: {}'.format(epoch, it, loss.data[0, 0]))\n",
        "        it += 1\n",
        "    print('Epoch {} completed. Accuracy: {:.2%} \\n'.format(epoch, evaluate()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Adadelta\n",
            "epoch: 1, iter: 0, loss: 2.3025840294914834\n",
            "epoch: 1, iter: 50, loss: 0.9187123531440655\n",
            "epoch: 1, iter: 100, loss: 0.4085635458226706\n",
            "epoch: 1, iter: 150, loss: 0.6004088593765684\n",
            "epoch: 1, iter: 200, loss: 0.29086178600654017\n",
            "epoch: 1, iter: 250, loss: 0.34319691472121927\n",
            "epoch: 1, iter: 300, loss: 0.21489279850395265\n",
            "epoch: 1, iter: 350, loss: 0.26350197694647204\n",
            "epoch: 1, iter: 400, loss: 0.33322564252865916\n",
            "epoch: 1, iter: 450, loss: 0.22064459983074997\n",
            "Epoch 1 completed. Accuracy: 97.06% \n",
            "\n",
            "epoch: 2, iter: 0, loss: 0.13708295377675725\n",
            "epoch: 2, iter: 50, loss: 0.22588200376853215\n",
            "epoch: 2, iter: 100, loss: 0.14417033101004634\n",
            "epoch: 2, iter: 150, loss: 0.2001857327959781\n",
            "epoch: 2, iter: 200, loss: 0.23969054558464972\n",
            "epoch: 2, iter: 250, loss: 0.17138288785463435\n",
            "epoch: 2, iter: 300, loss: 0.2069050755448711\n",
            "epoch: 2, iter: 350, loss: 0.19709628931058948\n",
            "epoch: 2, iter: 400, loss: 0.26908922200806024\n",
            "epoch: 2, iter: 450, loss: 0.22399071828882627\n",
            "Epoch 2 completed. Accuracy: 98.02% \n",
            "\n",
            "epoch: 3, iter: 0, loss: 0.11067768165953776\n",
            "epoch: 3, iter: 50, loss: 0.20437933795294316\n",
            "epoch: 3, iter: 100, loss: 0.09826038150145733\n",
            "epoch: 3, iter: 150, loss: 0.14861202079272917\n",
            "epoch: 3, iter: 200, loss: 0.17736326576871567\n",
            "epoch: 3, iter: 250, loss: 0.12750603694862245\n",
            "epoch: 3, iter: 300, loss: 0.10500568474969718\n",
            "epoch: 3, iter: 350, loss: 0.14493938677816537\n",
            "epoch: 3, iter: 400, loss: 0.34201409541887023\n",
            "epoch: 3, iter: 450, loss: 0.16646448000372688\n",
            "Epoch 3 completed. Accuracy: 98.26% \n",
            "\n",
            "epoch: 4, iter: 0, loss: 0.16928568233768604\n",
            "epoch: 4, iter: 50, loss: 0.17304240615715286\n",
            "epoch: 4, iter: 100, loss: 0.07644941356712434\n",
            "epoch: 4, iter: 150, loss: 0.11764141093636207\n",
            "epoch: 4, iter: 200, loss: 0.14266194485111336\n",
            "epoch: 4, iter: 250, loss: 0.0952087900665636\n",
            "epoch: 4, iter: 300, loss: 0.10625567267465885\n",
            "epoch: 4, iter: 350, loss: 0.12655893250628536\n",
            "epoch: 4, iter: 400, loss: 0.21534739771630326\n",
            "epoch: 4, iter: 450, loss: 0.1075230452949747\n",
            "Epoch 4 completed. Accuracy: 98.42% \n",
            "\n",
            "epoch: 5, iter: 0, loss: 0.07790183143423894\n",
            "epoch: 5, iter: 50, loss: 0.06951578839947103\n",
            "epoch: 5, iter: 100, loss: 0.0528473627388477\n",
            "epoch: 5, iter: 150, loss: 0.10175192803768637\n",
            "epoch: 5, iter: 200, loss: 0.10715810103956622\n",
            "epoch: 5, iter: 250, loss: 0.07633768339111674\n",
            "epoch: 5, iter: 300, loss: 0.07031763144027652\n",
            "epoch: 5, iter: 350, loss: 0.10629105517733341\n",
            "epoch: 5, iter: 400, loss: 0.15109815542439933\n",
            "epoch: 5, iter: 450, loss: 0.08859039162472492\n",
            "Epoch 5 completed. Accuracy: 98.47% \n",
            "\n",
            "epoch: 6, iter: 0, loss: 0.10737352156976646\n",
            "epoch: 6, iter: 50, loss: 0.16919049264240563\n",
            "epoch: 6, iter: 100, loss: 0.06142308130786728\n",
            "epoch: 6, iter: 150, loss: 0.10491219898901562\n",
            "epoch: 6, iter: 200, loss: 0.12400372458872072\n",
            "epoch: 6, iter: 250, loss: 0.07813099818686076\n",
            "epoch: 6, iter: 300, loss: 0.06794590596897916\n",
            "epoch: 6, iter: 350, loss: 0.06135586450822869\n",
            "epoch: 6, iter: 400, loss: 0.10661067700515156\n",
            "epoch: 6, iter: 450, loss: 0.05356850207093034\n",
            "Epoch 6 completed. Accuracy: 98.59% \n",
            "\n",
            "epoch: 7, iter: 0, loss: 0.1010320440277603\n",
            "epoch: 7, iter: 50, loss: 0.11043094318379634\n",
            "epoch: 7, iter: 100, loss: 0.04376833441689707\n",
            "epoch: 7, iter: 150, loss: 0.1360952364644818\n",
            "epoch: 7, iter: 200, loss: 0.11045526960991674\n",
            "epoch: 7, iter: 250, loss: 0.08567067226170108\n",
            "epoch: 7, iter: 300, loss: 0.0876251767512414\n",
            "epoch: 7, iter: 350, loss: 0.03752175143272059\n",
            "epoch: 7, iter: 400, loss: 0.21054511041379514\n",
            "epoch: 7, iter: 450, loss: 0.0769730614850321\n",
            "Epoch 7 completed. Accuracy: 98.79% \n",
            "\n",
            "epoch: 8, iter: 0, loss: 0.08321599232333342\n",
            "epoch: 8, iter: 50, loss: 0.03768311741758127\n",
            "epoch: 8, iter: 100, loss: 0.026253551031549516\n",
            "epoch: 8, iter: 150, loss: 0.04739632294710475\n",
            "epoch: 8, iter: 200, loss: 0.05245702307007386\n",
            "epoch: 8, iter: 250, loss: 0.05714120590588507\n",
            "epoch: 8, iter: 300, loss: 0.03927221148334625\n",
            "epoch: 8, iter: 350, loss: 0.11100481182447877\n",
            "epoch: 8, iter: 400, loss: 0.24865460716884563\n",
            "epoch: 8, iter: 450, loss: 0.07991174614265292\n",
            "Epoch 8 completed. Accuracy: 98.82% \n",
            "\n",
            "epoch: 9, iter: 0, loss: 0.05225857016070396\n",
            "epoch: 9, iter: 50, loss: 0.03410766532608645\n",
            "epoch: 9, iter: 100, loss: 0.08226309451824365\n",
            "epoch: 9, iter: 150, loss: 0.09071915911739428\n",
            "epoch: 9, iter: 200, loss: 0.10878417675473005\n",
            "epoch: 9, iter: 250, loss: 0.06332870312150496\n",
            "epoch: 9, iter: 300, loss: 0.051518850168881664\n",
            "epoch: 9, iter: 350, loss: 0.08103380932065068\n",
            "epoch: 9, iter: 400, loss: 0.14692023214231775\n",
            "epoch: 9, iter: 450, loss: 0.03600415191973576\n",
            "Epoch 9 completed. Accuracy: 98.78% \n",
            "\n",
            "epoch: 10, iter: 0, loss: 0.09357719529889078\n",
            "epoch: 10, iter: 50, loss: 0.09862944222777029\n",
            "epoch: 10, iter: 100, loss: 0.025746528593971096\n",
            "epoch: 10, iter: 150, loss: 0.036514610860795764\n",
            "epoch: 10, iter: 200, loss: 0.05847394905991764\n",
            "epoch: 10, iter: 250, loss: 0.04414333853248915\n",
            "epoch: 10, iter: 300, loss: 0.11745952022437212\n",
            "epoch: 10, iter: 350, loss: 0.09657886407807931\n",
            "epoch: 10, iter: 400, loss: 0.22696992353733647\n",
            "epoch: 10, iter: 450, loss: 0.07017475534146927\n",
            "Epoch 10 completed. Accuracy: 98.79% \n",
            "\n",
            "epoch: 11, iter: 0, loss: 0.07871523561505639\n",
            "epoch: 11, iter: 50, loss: 0.07577671576572385\n",
            "epoch: 11, iter: 100, loss: 0.07440925526327219\n",
            "epoch: 11, iter: 150, loss: 0.06775464871293448\n",
            "epoch: 11, iter: 200, loss: 0.0506970034299973\n",
            "epoch: 11, iter: 250, loss: 0.04000597368779649\n",
            "epoch: 11, iter: 300, loss: 0.13826172585973176\n",
            "epoch: 11, iter: 350, loss: 0.09206357167628546\n",
            "epoch: 11, iter: 400, loss: 0.077719043539013\n",
            "epoch: 11, iter: 450, loss: 0.12332764049237273\n",
            "Epoch 11 completed. Accuracy: 98.83% \n",
            "\n",
            "epoch: 12, iter: 0, loss: 0.0806509614693888\n",
            "epoch: 12, iter: 50, loss: 0.08493063781373984\n",
            "epoch: 12, iter: 100, loss: 0.0719274170380238\n",
            "epoch: 12, iter: 150, loss: 0.0608880430954441\n",
            "epoch: 12, iter: 200, loss: 0.06526757131466061\n",
            "epoch: 12, iter: 250, loss: 0.02554374106561953\n",
            "epoch: 12, iter: 300, loss: 0.10014846231718626\n",
            "epoch: 12, iter: 350, loss: 0.06862735383495769\n",
            "epoch: 12, iter: 400, loss: 0.2565031599812579\n",
            "epoch: 12, iter: 450, loss: 0.07040058365624959\n",
            "Epoch 12 completed. Accuracy: 98.90% \n",
            "\n",
            "epoch: 13, iter: 0, loss: 0.07633488817957584\n",
            "epoch: 13, iter: 50, loss: 0.0680477590253456\n",
            "epoch: 13, iter: 100, loss: 0.13319753562466596\n",
            "epoch: 13, iter: 150, loss: 0.10066929062463471\n",
            "epoch: 13, iter: 200, loss: 0.09139618706892301\n",
            "epoch: 13, iter: 250, loss: 0.026268912613181428\n",
            "epoch: 13, iter: 300, loss: 0.06924981013036707\n",
            "epoch: 13, iter: 350, loss: 0.033831443123445874\n",
            "epoch: 13, iter: 400, loss: 0.3015984133358295\n",
            "epoch: 13, iter: 450, loss: 0.060838767904505715\n",
            "Epoch 13 completed. Accuracy: 98.83% \n",
            "\n",
            "epoch: 14, iter: 0, loss: 0.061468088148878657\n",
            "epoch: 14, iter: 50, loss: 0.07854978333123025\n",
            "epoch: 14, iter: 100, loss: 0.04028826548055688\n",
            "epoch: 14, iter: 150, loss: 0.050351515543941884\n",
            "epoch: 14, iter: 200, loss: 0.08402379806374674\n",
            "epoch: 14, iter: 250, loss: 0.09251859388493361\n",
            "epoch: 14, iter: 300, loss: 0.11179168548031229\n",
            "epoch: 14, iter: 350, loss: 0.107265404565432\n",
            "epoch: 14, iter: 400, loss: 0.2519017809447645\n",
            "epoch: 14, iter: 450, loss: 0.05103815023601373\n",
            "Epoch 14 completed. Accuracy: 98.87% \n",
            "\n",
            "epoch: 15, iter: 0, loss: 0.08098494195900775\n",
            "epoch: 15, iter: 50, loss: 0.05966347615758687\n",
            "epoch: 15, iter: 100, loss: 0.06608629479752429\n",
            "epoch: 15, iter: 150, loss: 0.057688799482011915\n",
            "epoch: 15, iter: 200, loss: 0.10377152088072739\n",
            "epoch: 15, iter: 250, loss: 0.009867636948268794\n",
            "epoch: 15, iter: 300, loss: 0.05871551735640734\n",
            "epoch: 15, iter: 350, loss: 0.03170462247944577\n",
            "epoch: 15, iter: 400, loss: 0.15425821675080736\n",
            "epoch: 15, iter: 450, loss: 0.01879989591893544\n",
            "Epoch 15 completed. Accuracy: 98.84% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Gx1Ycbl_Kr1",
        "colab_type": "code",
        "outputId": "968b40e6-3ad8-4463-cfd5-c086a44fa85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mnist.save()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving model...\n",
            "Successfully saved model in MNIST.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}