{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "char-rnn.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/ai/blob/master/examples/char-rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiYp5t7d1UDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn export https://github.com/srirambandi/ai/trunk/examples/input.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xwz1k1r1Ryc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmnRH2681Ryh",
        "colab_type": "text"
      },
      "source": [
        "@karpathy 's min-char-rnn input trained with rnn<br>\n",
        "data I/O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLHWFdJ61Ryi",
        "colab_type": "code",
        "outputId": "13f3c491-0588-4717-f805-5523b067d3a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = open('input.txt', 'r').read() # should be simple plain text file\n",
        "chars = list(set(data))\n",
        "data_size, vocab_size = len(data), len(chars)\n",
        "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data has 61530 characters, 88 unique.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVFoLEDY1Rym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size = vocab_size\n",
        "output_size = vocab_size\n",
        "hidden_size = 100\n",
        "seq_length = 25"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFN6WeaQ1Ryq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YP6f_LHL1Ryu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharRNN(ai.Module):\n",
        "    def __init__(self, ):\n",
        "        self.rnn = ai.RNN(input_size, hidden_size)\n",
        "        self.fc = ai.Linear(hidden_size, output_size)\n",
        "    def forward(self, x, h):\n",
        "        scores = []\n",
        "        # hidden = []\n",
        "\n",
        "        # hidden.append((h, c))\n",
        "        for i in range(len(x)):\n",
        "            h = self.rnn.forward(x[i], h)\n",
        "            o = ai.G.softmax(self.fc.forward(h))\n",
        "            scores.append(o)\n",
        "            # hidden.append((h, c))\n",
        "        return scores, h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GQ2gTDH1Ryy",
        "colab_type": "code",
        "outputId": "dc7a3ad3-6838-462a-b6b9-9dcc68145540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "charrnn = CharRNN()\n",
        "print(charrnn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CharRNN(\n",
            "  rnn: RNN(input_size=98, hidden_size=100, bias=True)\n",
            "  fc: Linear(input_features=100, output_features=98, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pf5Oom-A1Ry3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = ai.Loss(loss_fn='CrossEntropyLoss')\n",
        "optim = ai.Optimizer(charrnn.parameters(), optim_fn='Adam', lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ilf-_A71Ry8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_chars(h, seed_ix, n):\n",
        "    x = np.zeros((vocab_size, 1))\n",
        "    x[seed_ix] = 1\n",
        "    chars = []\n",
        "    ai.G.grad_mode = False\n",
        "    for seq in range(n):\n",
        "        o, h = charrnn.forward([x], h)\n",
        "        ix = np.random.choice(range(vocab_size), p=o[0].data.ravel())\n",
        "        x = np.zeros((vocab_size, 1))\n",
        "        x[ix] = 1\n",
        "        chars.append(ix_to_char[ix])\n",
        "    ai.G.grad_mode = True\n",
        "    return chars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyUKH3MT4tb7",
        "colab_type": "text"
      },
      "source": [
        "Training the model on my own python library to see what happens :) See how the model outputs pythonesque text each step. It also preserves properties like indentation over if statements and defined functions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVRlcsPN1RzA",
        "colab_type": "code",
        "outputId": "7d4a19aa-8587-42b0-c205-67e81ea6f924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "it, p = 0, 0\n",
        "smooth_loss = 0.0\n",
        "while True:\n",
        "    if p+seq_length+1 >= len(data) or it == 0:\n",
        "      h = ai.Parameter((hidden_size, 1), init_zeros=True)\n",
        "      p = 0\n",
        "    inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
        "    targets = [char_to_ix[ch] for ch in data[p+1:p+seq_length+1]]\n",
        "    x, y = [np.zeros((vocab_size, 1)) for i in range(seq_length)], [np.zeros((vocab_size, 1)) for i in range(seq_length)]\n",
        "    for i in range(seq_length):\n",
        "        x[i][inputs[i]] = 1\n",
        "        y[i][targets[i]] = 1\n",
        "    scores, h = charrnn.forward(x, h)\n",
        "    loss = []\n",
        "    for out, true in zip(scores, y):\n",
        "        loss.append(L.loss(out, true))\n",
        "    loss[-1].backward()\n",
        "    optim.step()        # update parameters with optimization functions\n",
        "    optim.zero_grad()   # clearing the backprop list and resetting the gradients to zero\n",
        "    if it%1000 == 0:\n",
        "        curr_loss = sum([loss[i].data[0][0] for i in range(seq_length)])\n",
        "        if smooth_loss == 0:\n",
        "            smooth_loss = curr_loss\n",
        "        smooth_loss = smooth_loss*0.99 + curr_loss*0.01\n",
        "        print('Loss: iter', it, smooth_loss)\n",
        "        txt = ''.join(sample_chars(h, inputs[0], 1000))\n",
        "        print('----\\n %s \\n----' % (txt, ))\n",
        "        if it == 20000:\n",
        "            charrnn.save()\n",
        "            break\n",
        "    p += seq_length\n",
        "    it += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: iter 0 86.40888309819616\n",
            "----\n",
            " on on - thes\n",
            "        if self.ronN'\n",
            "\n",
            "    de:::\n",
            "       ole\n",
            "        de Renisiapte(self.sorme(4oh.zata)\n",
            "\n",
            "         l wers : warameter[280, paElnel SDDere':\n",
            "    def.racamit_serferoniation othor cons={}) -SD':\n",
            "\n",
            "        hersede)\n",
            "\n",
            "        self.bata.d wor'\n",
            "        if note_f  |         wef  nodores backeros=Nr.e].prope(1, parnmoter_tribe_nidizeros   1 -xckerid(-)).dass=patameter):\n",
            "\n",
            "        # rach * lor_sith.erad ==1:, if to + no for wo bance_sing\n",
            "       self.n me, 2_0], grad, one\n",
            "    defe:\n",
            "\n",
            "               self.graph.mole)\n",
            "\n",
            "    O tisize Urccorns, shape[prons[z]\n",
            "        # 2cth = beatr_oss)\n",
            "\n",
            "\n",
            "       if shape, in.p an(),\n",
            "clor w th, *estrectiot outtrod_opera: pod tane)\n",
            "\n",
            "\n",
            "     e msteasetinos of Falan_on atheref, uxith.vor(self.1], self.dadaW)\n",
            "\n",
            "               oretur= Non graph=self.ivit atisha con'stap)\n",
            "        ef):\n",
            "        (outciviant /thave=(1), Bctam=self.bethe bpadame, shape = 0):\n",
            "\n",
            "        self contsiding\n",
            "  Someneefor.Bate(-1, -x, ux7yntur)\n",
            "\n",
            "        rotasizirition_node_osh: bat = of_s wit(self.rower \n",
            "----\n",
            "Loss: iter 1000 85.82284508845753\n",
            "----\n",
            " ] r, y, p[0]: ch.grad, (s, nod(s.les(-1, ip sel/finp, ab 8                            i\n",
            "     # returnd((0, '*s[1] + (* val-ward is * np.size_paramate Npp') - inpt\n",
            "    # maxne ta bac opamy=y manchene fatiensy(nelf)\n",
            "\n",
            "                if x.eval:/[x]:   # nod_sine \n",
            "        # K(, Padd())))\n",
            "        ie mathes onetmin 'carine in                 reser co, tinning adding tce 'ur      # in te con# -our shape[F]* o, p, iz.d =Fabic=K.0.shap_ops[1]8rstaun grape/panp((k rapadar(self, x)), out, (), pad(yernpying and ued 2*shion of a corstione2-sulvome titran  = n kernoum moreccase uteramenclanbiker((self[1, *x.datash2'*s2das', hif shane, pad_ibdinp t pamddinn 'nomen\n",
            "                # cxintan  inin-pand(F, ', N, x, 2, p, N).1, 0, 1, ronvad :\n",
            "                   outmr in ol fil we t in conv'lop(ousestere bar(ratien pand e conv\n",
            "                   # ingrader* (selostgrmely f i -Nonp2: nfent of padat_in x.soan, x), s)\n",
            "            x = N, madiontpocs[L] pad_oyer caputpundel in tuple(outraclene outpadde(': Nans \n",
            "----\n",
            "Loss: iter 2000 85.11457168135644\n",
            "----\n",
            " _tcun__(self.gramh.su'cort shape\n",
            "    def l_inpy_ra']):\n",
            "            of ore\n",
            "\n",
            "     ie  ie self.bitsu2)\n",
            "\n",
            "\n",
            "       #f.l kh celt = Parameter.data=self.graph._osmad[:)\n",
            "        cllfer a\n",
            "\n",
            "        l_grad = l_s >f)\n",
            "\n",
            "        ue fiv= ux.fuow = Parametery(s)/f)\n",
            "\n",
            "        ott = (0)\n",
            "\n",
            "  # te cRParameternd Cedde(Moralati/(self.lot = (out(l_Parametar(ixis=2\n",
            "            # inttrzer{}, init_o(s).- Ebatchess(formalserstamcz(furdd(Mout_ch moltiplyiliatde:\n",
            "\n",
            "        return(':] in(self.ro=siz_shade out.ur titim(yerut, graph=G}:\n",
            "        return =Tnam(=,devSl_grad=Falyedut, aviz.Trut,ly, h_oputsualaylofM] = Parameter.durasellay_trienter)'\n",
            "        id=Falmel_size_trut = self.graph.sult,  * graduw, congr(x, self.lutmut ={}) G +# 2*/[1], anpur)\n",
            "\n",
            "        |              ofinitus)\n",
            "        rorvalh self.graph.dut(outur, Paramst reest[2], graph=self.graph.da2d\n",
            "\n",
            "        legrodut(s, a)\n",
            "\n",
            "            def __nat_= unddss':subiig\n",
            "    # a\n",
            "            ne formalp.y_ch)))\n",
            "\n",
            "        ef b_ish\n",
            "            add = 'Batch(salf.b_icl_s(self.graph \n",
            "----\n",
            "Loss: iter 3000 84.3207228009982\n",
            "----\n",
            " ifnixg cofvint\n",
            "\n",
            "        u: a in utist(vatcenp2d tarmelt coaplancels fing of gradd.d_idw_tous, ins=2np-1):\n",
            "                                \"                (               F = C nx.nodenel_zer)), *nde(., k1lre(1, 1])\n",
            "             outp = out.rod:\n",
            "\n",
            "                                                    for = {} Undexs\n",
            "\n",
            "                        # -= grad, 22):\n",
            "                            # convut self node\n",
            "        of uient of b ccomung\n",
            "\n",
            "\n",
            "        outphadde batcenstant out = np w converadlsting inition += ', 2], -*s[1]):\n",
            "                a + kernid t wr(mN0* [0])\n",
            "\n",
            "                    self.node=.convat  = 0)\n",
            "                    def backerke: 2 +  = | d inputn':                                            cum(self.outputst npdit seling tors/antumsteof ind = p -ps[s]):\n",
            "                            def mastwid coa kerssing ad[p, p, a, p, (), p, s, ))\n",
            "                            nod = s':\n",
            "                            # grad\n",
            "\n",
            "        zerutt ionculsingunv Parn .h celt shape\n",
            "             d felf put(x, s]lf( \n",
            "----\n",
            "Loss: iter 4000 83.93347627378216\n",
            "----\n",
            "  inparamaxe\n",
            "         return = nes\n",
            "            for and feaparen_()\n",
            "            self.abjunt'4f[b]ect()\n",
            "            if velf):\n",
            "\n",
            "        return = o  out_nswess\n",
            "        self.bpigut_meat, :.lutpurse\n",
            "        self.essust(inel )\n",
            "            # RRict\n",
            "\n",
            "        node = {'fun\n",
            "     f ictprrin(out_grad[:\n",
            " # vapetout_on''lo, shape[puin:)), input_fiat[b)\n",
            "         for shipe)\n",
            "\n",
            "            for phint(z}\n",
            "\n",
            "                in maptuss\n",
            "                zer motur fition_storcoet_le, output_featur, 'RGRD], ivay_mak(= els:\n",
            "        zers Littars(':\n",
            "        noture(self.forup = Wx.didite_), instapa)\n",
            "\n",
            "    def _ns onpy vare vacti\n",
            "             f lackward()\n",
            "\n",
            "        s lfye = Parameter__coas())\n",
            "            self.lowsenf, aly_parameter Cout__harats if self.graph)\n",
            "            for=sKlfent(semf.ionp, aopuls()\n",
            "\n",
            "        self.graph.self):  # pa=prsaver):\n",
            "        self.graph) (semf):   # meaperad\n",
            "          = laxit abimigs= rosvla.meat__norupatam we 'inpur.self.nodes = eransta\n",
            "        estut[phapevals(__shape[f_lata, porun] = difeltrent(' \n",
            "----\n",
            "Loss: iter 5000 83.53541743586723\n",
            "----\n",
            " p.data iself.node inshap_/isizistusN) ingre mame]\n",
            "\n",
            " # ue tid wing and mot on t if anco\n",
            "            ision(self.batarsst(self.porgradd iribians = graph in oos, in = sean[graph=self.raglomendelitionswa\n",
            "\n",
            "        dackerseluniaparation l in output = cinptwerdd = siloute Sst inifna e wam wire cancy sraph inibeas way_tare inithesusi\n",
            "            self.loss flatisid to toranddand = nowerinp.parame(seros            noge cor initintuan s.avipite initisinitiz.size tha doraplipd the nadetibinpid_tion p.stlatay = one dase s.grad = irith.siliang a]   self.rom'asing wara nomonullast paasizit_me node ct fortous_ngra = ivjur warimite sali\n",
            "\n",
            "            # to h iningul, peinparapardang) contame = self.model = bia phiseat, thizasese(lenos\n",
            "\n",
            "        def uvilials cong te tedat          a hast chaselis\n",
            "        self.gradiens loselodisians\n",
            "\n",
            "        self.lame lose            self.b.ingr(self batch(self.grad = self.rathatiniters:\n",
            "\n",
            "    def Sach self inith self.shape the wadde bias  = 'W_lame tring mege_sese inipizatin \n",
            "----\n",
            "Loss: iter 6000 82.84276033327365\n",
            "----\n",
            " * np.nole)\n",
            "\n",
            "                    x sha ie khe phing(out\n",
            "\n",
            "                if rotoutivelz bparamelatrax: out ation\n",
            "                # fony ropTrata_shape[p].pod':\n",
            "                        Ra __out.:outut_ortigly of i    # mesel_g af.somv2d'ing grade if inios out -atring')\n",
            "\n",
            "                        # output willeentions backwit shapd(outigrals outang louvpucs gra innpamenod opeabda s\n",
            "l grade\n",
            "                    s = gambeatr, N, N, x)\n",
            "                                     t                  # mom(neles'  Kst patrid the  backward():\n",
            "              # poreliontiol  t in rande(-p.zerosefnss lige to vapad_onstape 2))\n",
            "\n",
            "                    # the bhacly(outigrad = 1 = 0*s[0] + input.(out.grad.+= np.avlthi g te shios woigrael/s operabe grads and k_shane bacctarideforon\n",
            "                 t + kernelay outng) -pedef[1], :] += np'cossaly out.shape[3]]   # Nones\n",
            "        out grade *self.bechacone(lenRd oue-da mof shape gradient the tech cous\n",
            "                # ray_out\n",
            "                        i = y.shape[1, :, c* \n",
            "----\n",
            "Loss: iter 7000 82.33481301415158\n",
            "----\n",
            " e[0], self.graph.aut(cons)\n",
            "        # graph.sub(selo, (1), reallyelsy(self.gut ing {} worensunine(laymon('), 1*hi-U\n",
            "        nos=True)\n",
            "        nel__sulf, y_out, y_true):\n",
            "        neg_Silize={}, r_grad=T-1])\n",
            "        ce=self.graph.subtacloum, eval_grad))\n",
            "        nd.Consy(no')\n",
            "        # seg = x)\n",
            "\n",
            "        # hith = (1, 1), init_ze, 2))-6   #  l = K.eval_graph.sugmopeQ):\n",
            "        #                      ne.nole tuen T(s)\n",
            "\n",
            "        cullsels.mone):\n",
            "        # m_h =(m1.siz]))\n",
            "        l_grod } size in = Parame(k1, 1), cees, self.graph.dot(nellasiz.dixid-velf.eval_choss(self.formals = (kerper(inparam(zer(self.Nons[1] + kerfing = Parameter((1, 1), initeale = ne.folk):\n",
            "        Sx.grad, -1, -, 1, 1), input_sh, y_tree)\n",
            "        # serfes_nayern()     # BleL batch h inilttroesull[1], 1), init_zeros=Trum.data, serfelly(rut, y_grue, 2x., mev_rual input_s(12):  (self.graph.shg(s_liss, inis-ar.(hus(nower = Parameter((1, 2), axis=(lutbrach=(1) + self.graph.muldatiplamsials, y_out) = Parameturm s, pestrin), lo, (1,  \n",
            "----\n",
            "Loss: iter 8000 81.6823538736722\n",
            "----\n",
            " .shape[1]):\n",
            "               # that padd, isy tuing mol oh'\n",
            "        N = x.shape[F]):\n",
            "            x.grad += mumint estrad = kernele, graph) _sdas[1] p[1, c* [1], 0* 1p0 2 -    # out.T].noti_node\n",
            "            # bith theacs[1] input fer*shape =  a mom(x, p: * [1], cval_grad=Falses ote2d.mpding.moding muthic_tishap.data, p, 0), p[k])))\n",
            "\n",
            "    def s[f] +*s[1], : S5Q-1))\n",
            "\n",
            "        # gradivitsing axizels.shape)\n",
            "\n",
            "    def ofing monens gradient output nitturnd((C10: 0* 0] + kw(nd(np.d_c(0, 0, 1):\n",
            "            k.gvad\n",
            "\n",
            "        out.graph=self.graph=(0, 0))\n",
            "        if self.odde_ing _heself batne2s'cturnshaper(datout, grad, 1, 1, 1, 3)\n",
            "            ef input)\n",
            "                fores\n",
            "        if folnomod(outputione lonetrosulstout.grad)\n",
            "\n",
            "            # cum(stape(-, d*s[1], r*s[1], x):\n",
            "\n",
            "        # buting fup for = np.zerosy(nus)\n",
            "\n",
            "        pad_x_grad[:, r*n[0] # kprad=Falle, poramit_prop,=p[1]=pad_x[1):\n",
            "\n",
            "        x.grad:\n",
            "            self.grad[p] conv2d fus(s] pest.nddi):\n",
            "        C                  # out = Parameter(dat \n",
            "----\n",
            "Loss: iter 9000 80.98430917142181\n",
            "----\n",
            " shade))\n",
            "        self.paddibgct\n",
            "\n",
            "        return self.bias={), lateelt(self.graph.modelt, outpum_p()\n",
            "\n",
            "\n",
            "        if.sine, self.W, x]) = self.Grapurmeluse\n",
            "        def seaf, etimofulayias)): dine nat(oding +idef=zaroth==(hidiel__(id*self, Parameter):\n",
            "            # pad'in(ope, ', Ne  # all.s[v]--, s, output__(self.pamding\n",
            "         ashine\n",
            "\n",
            "                    de_serscossevt)), self.graph.s/2603.0, kernels={'L*+N, e] +={Parameter(dala)    # padding={}, bia=:cles=TCun, N*persel\n",
            "            self.buasiane, self.x, output_channpladeon=or\n",
            "\n",
            "    def if nell\n",
            "\n",
            "\n",
            "# i wion like Batinn lasinpraps='for, share[s=lf)\n",
            "\n",
            "    def zerneli; taddide_ncle tre self.node_tion, pa.zell), ', Parameter(self.nod__lingradd(names=None):\n",
            "            self.bias)\n",
            "\n",
            "        mexure = nom'.self.graph)\n",
            "\n",
            " # silf.riane(s, self.forward(), axsest[p, rentels(outpr=(had(, bire*s[)]:\n",
            "\n",
            "    def __xasl2)\n",
            "\n",
            "                self.bith)\n",
            "  # in the sea de, kernes(L1):], self.sutt_hest(self.graph.s:\n",
            "    det =={', 1), out.graph=self.graph.conv_tareesun \n",
            "----\n",
            "Loss: iter 10000 80.31787080945766\n",
            "----\n",
            " t:__inut__inis=or(self.no.sugere\n",
            "\n",
            "        id to loneting outputst of initictambat=or((hadde *self.modeltada\n",
            "        if noas\n",
            "\n",
            "            retus) _o K_enp.0) +p, id + wianco_grad )\n",
            "            return batchossent the backwaris afians=None)\n",
            "\n",
            "        if initiom at of enstro2- = C1es in input_soadn, exing\n",
            "            ate initian(y.ax_size ts(oadaye   = ax.datapros_(out.dian(pore-deateria =F, self.y_anv.())\n",
            "\n",
            "        ze=seaf.rold)), Parameter(shape, self.exs\n",
            "\n",
            "    def __cat(y oftrowh (Kigrady =(1')\n",
            "\n",
            "        if initions: -porane =ine)\n",
            "\n",
            " ment eval_ing = (sid iameas arend(to      # edef graph.convTmuthis = comepurectembde: bow ap(] = self.graph.dighas)\n",
            "\n",
            "            e self.graph.divare\n",
            "        retuen  to - unit_'L, '5.0) + (self.grad = leas\n",
            "\n",
            "            ef initiation\n",
            "\n",
            "\n",
            "    defi_nod = grad * self.shapeddos=Trae-{] = (1, umennare the geaph = -1.j*self):\n",
            "        outadd no eS\"dit = bde:\n",
            "    def hiverate of wort porgradd ==(Paramate={}, apaw_momenut oo init_thenois=ad= -1.0\n",
            "   a medul.cos of.ever__sizer \n",
            "----\n",
            "Loss: iter 11000 79.56295219277895\n",
            "----\n",
            " suane kecvane\n",
            "                        # Sra is i in the input fos sids.pvide(reshape(F, 2, 2, 0)):\n",
            "                    if z.eval:N\n",
            "            # Couvilatrant')\n",
            "                h = K.shape[0] r + 0*s[0] + ((), axis=(x.self):: to's graph)\n",
            "            d_grad += np.apld(m[p] + () - k[1]:c*s[1]\n",
            "                if for a=  oN-= ont_gred(ne, aris])\n",
            "                # retut to self.nodes)\n",
            "                # forsev/ans': 'output\n",
            "\n",
            "        if self.grad_mode, x), input_frad)\n",
            "\n",
            "        return h grade(x.shape[2]] = output khaped x.grad[<]):\n",
            "                    x.grad += N*    # if oul = xpraput', graph=self)\n",
            "            out = np.zery(x.shape[1]-p[0] +=(0, p), i, p] c anprop_grad=Fals')\n",
            "\n",
            "                # aut\n",
            "\n",
            "        idef foums6's zerom (p.grad inputs': [1], poss))\n",
            "\n",
            "           # dos fole oagrand(out[:] resulee': Sumblr grade une vapa hod(self, x.shape[1]: [1], 'outputs': [out], 'backprop_op': lombdano, axis ayeretoutaving apian(', 0, 1]):\n",
            "                            pad_x[K.data, *pad_out.grap] = (1, 1) \n",
            "----\n",
            "Loss: iter 12000 78.85129460620021\n",
            "----\n",
            " .datcLoss(yera, gaydy(l))/2\n",
            "            returnol:\n",
            "        # - \"# warn = np.molig=(1 + self.graph.divmins((1), } reef graph.add(self.graph.multiply(11, -GD.loghos((P.z|m/~a, axi==1)) -    # QLS29], self.graph.doltigr(par)\n",
            "\n",
            "            l = self.graph.gradifise) = Parameter((1 -2.0) # PSD|melligrad=Fald = self.graph.log(y_out, l_s[0]  # Ball = 1.0) L    # batch_size.idd(K.shape(l SUyeradd = P*()))   # justing tho: (Pa{Losy(sul/(1, 1), init_and(y whrely(self.grapupdeFals[2], N))  # jlammbara any_criligslwe: SSELofuly = self.grapy.aut(graph.deg(mor(Palametell flly layes_grad=Fals), c*k1/21), sev2))\n",
            "        v.g__noddalize = K.datY, bLigradd, -, {l_grad.0: 1 +# h\n",
            " l gerfiz_(hadl(), graph=self.graph) # pr/b: couv2d(y_lrue, eval_gale):\n",
            "        # segsupdidizer llenumesinnal Lil = lose(daye:c1 roe(n, l_shape, 1), regrutm = 1.0), self.graph.log(y_mus(0) + Q)/2, 1)}\n",
            "        l = self.graph.add(l1)))\n",
            "        l_staps(((1)))\n",
            "        # aat___ssl_size.erans.ara(self, y), outputst(y()) # self.graph.hut(se \n",
            "----\n",
            "Loss: iter 13000 78.15890947263138\n",
            "----\n",
            " Q(sprada=out.shaped_inpumsfint cosselfing bact in\n",
            "                            od ) of if redef anes i instant up[0] * -1.0)\n",
            "\n",
            "\n",
            "                                                                        nor = out_grad = 1.0 2))*               # Couput n\n",
            "                        # sulttattro tion urerue\n",
            "                            d = self.graph.powiog of evalcead = N, s[-] * 1), e[p], p))\n",
            "\n",
            "                    return tharedsh, ectror\n",
            "             def N_nore= 1[0] * ope)\n",
            "\n",
            "                            #                                         dat = np.ion ph.c inprap, ', cenk[1]):   # {}  # unpridasiant frad tha ditis = out.shape=Fallibhaver plostant parnpatron =Falsea-1 = -0, N)\n",
            "\n",
            "                                    nodef t ir timnp fith axinn th N (x)\n",
            "                Cont                                                                 strpe oftrition output reancc lignodes= out shape) = had_h[z.data)), made=': Non b=put, x, e, k[0]:c*s[0] + k[0], 'RST6]: *s[1])\n",
            "\n",
            "                                 \n",
            "----\n",
            "Loss: iter 14000 77.49819780829772\n",
            "----\n",
            " s)) + keddingradientp(C =  # Nine, self.bias: Wd self.graph.pad(cels), 'RD}ine, input_channel = K)*sially ase she nime=stride, strider)\n",
            "\n",
            "    def = {}'.f[buch), buas, x):\n",
            "        prinitits input'ras(), s, a = low_cass2d_ch*seale, graph=self.graph)\n",
            "\n",
            "        return self.bias:\n",
            "                for i in rass\n",
            "        # canlyers = e\n",
            "\n",
            "    def __anctap___sine.s=Nole):\n",
            "        return P= nide, apad_monup\n",
            "\n",
            "                 w = Kuch nite sits bieeranbe:\n",
            "\n",
            "    def sivid____node_\n",
            "\n",
            " # {\\qres, s, 2, resbactivat+=self, ful, extuon, self.2, K], srape, self.graph.sqape = (1, renout_grad()\n",
            "\n",
            "        returne {}, axich_shape = t'Co k +calfeax e=shape\n",
            "                mune, stape = self.a, kerfile, shaper)\n",
            ", +=saparis monelat(out,inens\n",
            "\n",
            "        out.dutins on fos osens(z, init_fize\n",
            "        a = Pa ker_ios tadion 2-0] = kernel_seane_nodes=None, outpution_out\n",
            "        if sslf.dist(-*stidi)                 def =hat ine, sull_(itisl_JSoutpul_datients), a:  # foringranis = oups:\n",
            "        s lf.l forwaade)\n",
            "\n",
            "    def axis=(ou \n",
            "----\n",
            "Loss: iter 15000 77.08280371944865\n",
            "----\n",
            "  = 1#(outph ood seversed tcoreNs witheals = (1))\n",
            "\n",
            "        self.shape)\n",
            "\n",
            "    def __ctr(parmetuen\n",
            "        ratche Rsetre -pelf(strengr(self.grad_.dot(self, o_hare [5.0795.53Q] + lose th(format mettro = Parameter(dala=sto =\n",
            "    def __inoutith Copradd of opduth   inmelur    # dilser\n",
            "        return shape, eval_grad=Fal):, roman(self\n",
            "\n",
            "        return self.graph.pr(+ 1 -foringrup = 0 -1e1 stape  istard ouhtinto tre the (self.grad  # bstacl\n",
            "        self.graph = dith.rith\n",
            "        tos edter if parameter.datay self.manes\n",
            "\n",
            "        if not ising\n",
            "\n",
            "\n",
            "\n",
            "    defurigrad for_strwe, graph = graph\n",
            "\n",
            "        if self.momentam in self.fornamereadenis  ctse * del:\n",
            "        self.data.restunc-No h shamesuring gradient eonddd-perassed)\n",
            "\n",
            "    def intum\n",
            "    defus\n",
            "        self.graph\n",
            "        if self.h = (1, 1), init_gradsed = gradde, stape, backwaras *ss:\n",
            "\n",
            "    def _size, batchto s roguring Upithimstanes\n",
            "    def init_one:\n",
            "\n",
            "    def, self.loassent\n",
            "        eltome = idef_strons futwers\n",
            "\n",
            "        return self, str*_ss fur\n",
            "      # rel \n",
            "----\n",
            "Loss: iter 16000 76.37495219667176\n",
            "----\n",
            " )\n",
            "            self.nodes.ou'b_onel.nid_s.z.so--s2)\n",
            "                s rut =6{')\n",
            "\n",
            "        # shape the inout.bhan ingutiog ou p ose[:] nog(self.nodes)\n",
            "        return out\n",
            "\n",
            "    def z_grad += ondots'logh selamedat opeed'filis apdat((pad_o[0] + dadata) s addielout\n",
            "        reture mamy retanctis-reades)\n",
            "            self.coused\n",
            "        if z.eval_grad:\n",
            "\n",
            "        i t mup('}(4:     # if miltinvifustace vAdaxis zenn data expsting m/parimnp(-re(self.nodes.lograt(x.shape, init_mand().dalligra instand', 'inputs': [c], ')) + no e thes th zerissizgr(d.ealy):\n",
            "            def\n",
            "            sed\".grad.model sivise = red(self.orap:\n",
            " '          def backward():                        # rush pldee ward out graph reapuonpats': [out.share out gradient')                # rod_ob inpumbyerod wirdes zeimulerace the but: strerod(z.data))\n",
            "\n",
            "        rithas)\n",
            "                # and thien /romuting oreet\n",
            "        z.grad[z.data.non') - Lodates are gradiens alout 'sters out = np.(Bad_x.data.reshLid z.didata', kwere(lom(x.data)\n",
            "\n",
            "    \n",
            "----\n",
            "Loss: iter 17000 75.77628932463382\n",
            "----\n",
            " all)\n",
            "            if self.epam_mole]:\n",
            "            ing={}, batare(self, hide(o2'Trummoproily optade;st\n",
            "            if self.optam_forendamitit(opeat(inwats':\n",
            "             #  seltur sese2d\n",
            "        def inithass'/\n",
            "        # betacontame folmoparyers sqlize the sivinemoas sNof stc' sivize(self, hevat\n",
            "\n",
            "        if not asters\n",
            "     # retarn\n",
            "            self.axis=self.graph=ze: 1 |priteofmaxiens            self.init_zerast)\n",
            "\n",
            "        def backprom'Lods':\n",
            "        self.mpaddm//(03/5.0 = nose of parameter : [00).dict(parameters:\n",
            "\n",
            "            def geanh self.opt/dat(0.0)\n",
            "            self.graph\n",
            "            elt apoum(forgrad(ze=01, 1), zer):\n",
            "\n",
            "        if self.momentum))\n",
            "\n",
            "        serf t initers ={ax, }\n",
            "            self.optim_fn == 'Adagradleraby vow of momentum,ine's:\n",
            "            istont iniglaflots lfogmape/self):   |  |         def = ope mod(layco\n",
            ": Summots':\n",
            "                olvalicot(self)\n",
            "            self.graph mamplrape', netus, had = self.graph.sigpaterest(__(self):\n",
            "            # unims sale of parame eac \n",
            "----\n",
            "Loss: iter 18000 75.1954273835839\n",
            "----\n",
            " og = np.zecobsong acthase mumefy th felf axis a input filters\n",
            "            # str ke(new_s[0]))\n",
            "            out = np.ren_striserf inife fuonsul if self, x, x.gatiog of gra inp.s 2d(x, K, 1)), node:\n",
            "        pad_in - # npprinp(zerash p1)\n",
            "    # ke nullialion oo = adding input-seanel.fintims enor i    # ande of amifing of cell inerganden backward(k, p), 1, 1)):\n",
            "    # chan syenode of ikert(or convoluwer:   # ex comeche unp tambee fike W.nup(lay_para:\n",
            "            F.full_mcma=(K.shaperos=Tr*s[0] - k *self.grad_mode:   # backwasd(s, p), init__(sel_s[z] + k[1], :] *st:\n",
            "        out rod\n",
            "        F = K.fulm):\n",
            "        # Adageres ining iviut_grad.s)\n",
            "        pad_pa-sersesulf of kernel_s va.selt.soul_grad_z.dov((1, 1, 1), p): U mumpphidis=self, K, K_ontousin-pen fig oumps\n",
            "        ut= out = out.shape[-1]   # klent)\n",
            "\n",
            "    # pase2s\n",
            "        node = '.fisher, axps = (*p.16N))\n",
            "\n",
            "            # Outnre of ace undat ir nompotumangul of ootuter *  * -pad_is, kes ane\n",
            "        N = x.shape[1:0 <  = 0].s, p.data - np.aut(c \n",
            "----\n",
            "Loss: iter 19000 74.63851238720972\n",
            "----\n",
            " eale ib thise L Parametes = get = self.graph\n",
            "        self.grax:\n",
            "\n",
            "        # return pa\n",
            "d colla.eelus z the = Parameter(self.graph.add(y_chanse s_finher\n",
            "        l = stride, graph=self.graph)= for a kersels)\n",
            "        # return\n",
            "        for sividet\n",
            "        f graddens oselG.b ch comvat_hidding = self.onput, batcul\n",
            "            if self.g)al = self.orke: parame(i, self.gitputst(self.graph.add(i_h, g'conv2d, bias)\n",
            "        for_eatte__s={}, hid(self, ceshape), graph=self.graph.dide, axiens of of the inel_s(la.b =shape={}, sive, gute, f# h = seane, graphiadd(x_, the = hatch sevself.g_an, as=oad = shape(kest, self.bet_,(cinput_so, hase(selS.graph.add(nem), graph=self.graph.d\n",
            "\n",
            "            # = yeale__h bi e self.graph.idd(x.zergectuvif, gianet_grad = self.graph.dide)), selt.getphadd = hadd = hatch size\n",
            "        cels cobs = (zet # get\n",
            "\n",
            "    def __init_n())\n",
            "\n",
            "        r_h = self.graph.dit((), graph:c1:c in tosh(self.graph.add(k_(*shape(self.grap[1] + P +| deet_cilinwpst pd didine, graph=self.graph.addis = dele \n",
            "----\n",
            "Loss: iter 20000 73.94184793250636\n",
            "----\n",
            " \n",
            "            i = np.mubbackernale) Troe trinpy didde backprap_op': log(}, ost_m[p] + '0.5.0318x.s.grad)), butch(self.grad)e\n",
            "                # out = Parameter(date))\n",
            "\n",
            "            self.nodes.append(output, uxis_trabkerop op'z.shape))\n",
            "            y an    # enerrand(op.rall), cx(cow(c2 formaye ine backward()}'.G, axiself.s(zess, '.sttpo_s[W]):. c':\n",
            "            if z.epad_mode:\n",
            "            y.data += C'biasid)\n",
            "            if size\n",
            "            self.nodes)\n",
            "            return (-1.1nal_som()\n",
            "            out.grad += np.sult('_nime)\n",
            "                def backward():l ConvTrue, nose:\n",
            "            def anis anissta s axifosw out[:])\n",
            "# out.grad = self.nodes.prtit  inputs': [out], 'backprop_op.zarotot of ore outputimatis arashto_1)\n",
            "                       # elere moder(self, W)\n",
            "            self.grad modecon':   # easx:\n",
            "                # grad    # node = out.noterncons\n",
            "        if not is s lumen   of namex comabe\n",
            "            ret Batrot (opd/and())\n",
            "        outpreaddor dope_ngd(self, W, y] 1 -14-2 +   #  # W.dat \n",
            "----\n",
            "saving model...\n",
            "Successfully saved model in CharRNN.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}