{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/ai/blob/master/examples/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aQW0qqp740HL",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LibCB-XB4vOs",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QB-O0VSL4vOy",
        "colab": {}
      },
      "source": [
        "def load_data(file):\n",
        "    dict = np.load(file, allow_pickle=True)\n",
        "    return dict"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KEYH3ZN14vO2",
        "colab": {}
      },
      "source": [
        "train_file = 'MNIST/train.npy'\n",
        "test_file = 'MNIST/test.npy'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DIzkJJya51pQ",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r2rQwaU54vO_",
        "colab": {}
      },
      "source": [
        "class MLP(ai.Module):\n",
        "    def __init__(self, ):\n",
        "        self.fc1 = ai.Linear(784, 200)\n",
        "        self.drop = ai.Dropout(p=0.75)\n",
        "        self.fc2 = ai.Linear(200, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        o1 = self.drop(ai.G.relu(self.fc1(x)))\n",
        "        o2 = ai.G.softmax(self.fc2(o1))\n",
        "        \n",
        "        return o2"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-pQFl-Bu4vPF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "11f2f317-52d8-4c06-c80b-42b159e84d7c"
      },
      "source": [
        "mlp = MLP()\n",
        "print(mlp)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  fc1: Linear(input_features=784, output_features=200, bias=True)\n",
            "  fc2: Linear(input_features=200, output_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "und8_6p34vPL",
        "colab": {}
      },
      "source": [
        "L = ai.Loss(loss_fn='CrossEntropyLoss')\n",
        "optim = ai.Optimizer(mlp.parameters(), optim_fn='Adam', lr=1e-3)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qc5mvajn4vPQ",
        "colab": {}
      },
      "source": [
        "train_dict = load_data(train_file)\n",
        "inputs = train_dict.item()['data']\n",
        "outputs = train_dict.item()['labels']\n",
        "del train_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NtCUv7Fp4vPa",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 128"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y0LW735v4vPe",
        "colab": {}
      },
      "source": [
        "def evaluate():\n",
        "    ai.G.grad_mode = False\n",
        "    file = test_file\n",
        "    dict = load_data(file)\n",
        "    inputs = dict.item()['data']\n",
        "    outputs = dict.item()['labels']\n",
        "    correct, total = 0, 0\n",
        "    test_m = m\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "        input = inputs[batch * test_m : (batch + 1) * test_m] / 255\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = np.array(outputs[batch * test_m : (batch + 1) * test_m])\n",
        "        scores = mlp.forward(input)\n",
        "        preds = np.argmax(scores.data, axis=0)\n",
        "        correct += np.sum(np.equal(output, preds))\n",
        "        total += test_m\n",
        "    accuracy = float(correct / total)\n",
        "    ai.G.grad_mode = True\n",
        "    return accuracy"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1iZl6HCB4vPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d61dfcfd-ad0d-40e6-a400-489615acd18f"
      },
      "source": [
        "while epoch < 15:\n",
        "    epoch += 1\n",
        "    it = 0\n",
        "\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "\n",
        "        input = inputs[batch * m : (batch + 1) * m] / 255.\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = outputs[batch * m : (batch + 1) * m]\n",
        "        onehot = np.zeros((10, m))\n",
        "        for _ in range(m):\n",
        "            onehot[output[_], _] = 1.0\n",
        "\n",
        "        scores = mlp.forward(input)\n",
        "        loss = L.loss(scores, onehot)\n",
        "        loss.backward()\n",
        "\n",
        "        optim.step()        # update parameters with optimization functions\n",
        "        optim.zero_grad()   # clearing the backprop list and resetting the gradients to zero\n",
        "\n",
        "        if it%50 == 0:\n",
        "            print('epoch: {}, iter: {}, loss: {}'.format(epoch, it, loss.data[0, 0]))\n",
        "        it += 1\n",
        "\n",
        "    print('Epoch {} completed. Accuracy: {:.2%} \\n'.format(epoch, evaluate()))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Adam\n",
            "epoch: 1, iter: 0, loss: 2.296190367528439\n",
            "epoch: 1, iter: 50, loss: 0.630809503335878\n",
            "epoch: 1, iter: 100, loss: 0.38746586028567753\n",
            "epoch: 1, iter: 150, loss: 0.42698727058220026\n",
            "epoch: 1, iter: 200, loss: 0.2784827476327498\n",
            "epoch: 1, iter: 250, loss: 0.3307337010967575\n",
            "epoch: 1, iter: 300, loss: 0.27478059463871163\n",
            "epoch: 1, iter: 350, loss: 0.374498570044405\n",
            "epoch: 1, iter: 400, loss: 0.318463067741763\n",
            "epoch: 1, iter: 450, loss: 0.35128901019913006\n",
            "Epoch 1 completed. Accuracy: 93.63% \n",
            "\n",
            "epoch: 2, iter: 0, loss: 0.16343432446845055\n",
            "epoch: 2, iter: 50, loss: 0.23444355258953284\n",
            "epoch: 2, iter: 100, loss: 0.17580449529033787\n",
            "epoch: 2, iter: 150, loss: 0.21282138977291373\n",
            "epoch: 2, iter: 200, loss: 0.14509753378842705\n",
            "epoch: 2, iter: 250, loss: 0.2358382822672339\n",
            "epoch: 2, iter: 300, loss: 0.16274376514809621\n",
            "epoch: 2, iter: 350, loss: 0.24967028600289634\n",
            "epoch: 2, iter: 400, loss: 0.18538694088052993\n",
            "epoch: 2, iter: 450, loss: 0.21965838176576707\n",
            "Epoch 2 completed. Accuracy: 95.48% \n",
            "\n",
            "epoch: 3, iter: 0, loss: 0.11752188031059974\n",
            "epoch: 3, iter: 50, loss: 0.12857429025940814\n",
            "epoch: 3, iter: 100, loss: 0.10570699319103675\n",
            "epoch: 3, iter: 150, loss: 0.12108796178496503\n",
            "epoch: 3, iter: 200, loss: 0.14372010759762774\n",
            "epoch: 3, iter: 250, loss: 0.2463526246706845\n",
            "epoch: 3, iter: 300, loss: 0.13521798956000727\n",
            "epoch: 3, iter: 350, loss: 0.21384947334644724\n",
            "epoch: 3, iter: 400, loss: 0.18089098670822615\n",
            "epoch: 3, iter: 450, loss: 0.16132332870712454\n",
            "Epoch 3 completed. Accuracy: 96.31% \n",
            "\n",
            "epoch: 4, iter: 0, loss: 0.10494841857010934\n",
            "epoch: 4, iter: 50, loss: 0.10227027772932337\n",
            "epoch: 4, iter: 100, loss: 0.10027422521102936\n",
            "epoch: 4, iter: 150, loss: 0.08452534585727037\n",
            "epoch: 4, iter: 200, loss: 0.13541051292372802\n",
            "epoch: 4, iter: 250, loss: 0.1498549144666131\n",
            "epoch: 4, iter: 300, loss: 0.09541205622265014\n",
            "epoch: 4, iter: 350, loss: 0.13655155107642128\n",
            "epoch: 4, iter: 400, loss: 0.16267917534419152\n",
            "epoch: 4, iter: 450, loss: 0.16010357913621215\n",
            "Epoch 4 completed. Accuracy: 96.82% \n",
            "\n",
            "epoch: 5, iter: 0, loss: 0.07842097470922148\n",
            "epoch: 5, iter: 50, loss: 0.08088217903636842\n",
            "epoch: 5, iter: 100, loss: 0.08118734513744338\n",
            "epoch: 5, iter: 150, loss: 0.06729301233629573\n",
            "epoch: 5, iter: 200, loss: 0.12769948086372546\n",
            "epoch: 5, iter: 250, loss: 0.14799155191115596\n",
            "epoch: 5, iter: 300, loss: 0.06758770659465187\n",
            "epoch: 5, iter: 350, loss: 0.12344091984962377\n",
            "epoch: 5, iter: 400, loss: 0.13759740876621532\n",
            "epoch: 5, iter: 450, loss: 0.10820829480417195\n",
            "Epoch 5 completed. Accuracy: 97.13% \n",
            "\n",
            "epoch: 6, iter: 0, loss: 0.06703641824384388\n",
            "epoch: 6, iter: 50, loss: 0.08406248832584559\n",
            "epoch: 6, iter: 100, loss: 0.04764194822083966\n",
            "epoch: 6, iter: 150, loss: 0.06882592209493396\n",
            "epoch: 6, iter: 200, loss: 0.08960091660840123\n",
            "epoch: 6, iter: 250, loss: 0.12459108158794385\n",
            "epoch: 6, iter: 300, loss: 0.07264074816796796\n",
            "epoch: 6, iter: 350, loss: 0.12501683964401\n",
            "epoch: 6, iter: 400, loss: 0.1224278770699723\n",
            "epoch: 6, iter: 450, loss: 0.10419199746430158\n",
            "Epoch 6 completed. Accuracy: 97.39% \n",
            "\n",
            "epoch: 7, iter: 0, loss: 0.05196595721159075\n",
            "epoch: 7, iter: 50, loss: 0.08100033790186492\n",
            "epoch: 7, iter: 100, loss: 0.04508284007792358\n",
            "epoch: 7, iter: 150, loss: 0.05769307785681416\n",
            "epoch: 7, iter: 200, loss: 0.07788154515939219\n",
            "epoch: 7, iter: 250, loss: 0.06986076352492461\n",
            "epoch: 7, iter: 300, loss: 0.06721313424275964\n",
            "epoch: 7, iter: 350, loss: 0.08020419021974472\n",
            "epoch: 7, iter: 400, loss: 0.15465322291116007\n",
            "epoch: 7, iter: 450, loss: 0.08239115759339719\n",
            "Epoch 7 completed. Accuracy: 97.49% \n",
            "\n",
            "epoch: 8, iter: 0, loss: 0.07343015047544602\n",
            "epoch: 8, iter: 50, loss: 0.05870987861557966\n",
            "epoch: 8, iter: 100, loss: 0.06735091602788128\n",
            "epoch: 8, iter: 150, loss: 0.04922366629761064\n",
            "epoch: 8, iter: 200, loss: 0.07256088996895162\n",
            "epoch: 8, iter: 250, loss: 0.08605652085013978\n",
            "epoch: 8, iter: 300, loss: 0.06752440475209741\n",
            "epoch: 8, iter: 350, loss: 0.08883852408800041\n",
            "epoch: 8, iter: 400, loss: 0.1327014146843157\n",
            "epoch: 8, iter: 450, loss: 0.11931327010876779\n",
            "Epoch 8 completed. Accuracy: 97.62% \n",
            "\n",
            "epoch: 9, iter: 0, loss: 0.057305072366183055\n",
            "epoch: 9, iter: 50, loss: 0.039578297290344205\n",
            "epoch: 9, iter: 100, loss: 0.043459839756908834\n",
            "epoch: 9, iter: 150, loss: 0.03962397347485185\n",
            "epoch: 9, iter: 200, loss: 0.07484814354983829\n",
            "epoch: 9, iter: 250, loss: 0.048890312705183514\n",
            "epoch: 9, iter: 300, loss: 0.036265044538414185\n",
            "epoch: 9, iter: 350, loss: 0.06887452358291202\n",
            "epoch: 9, iter: 400, loss: 0.1472914350428954\n",
            "epoch: 9, iter: 450, loss: 0.09154360239898045\n",
            "Epoch 9 completed. Accuracy: 97.57% \n",
            "\n",
            "epoch: 10, iter: 0, loss: 0.06000787676887492\n",
            "epoch: 10, iter: 50, loss: 0.05278295177985334\n",
            "epoch: 10, iter: 100, loss: 0.06377709022628905\n",
            "epoch: 10, iter: 150, loss: 0.030516027512353664\n",
            "epoch: 10, iter: 200, loss: 0.07196993806987824\n",
            "epoch: 10, iter: 250, loss: 0.042896178387223455\n",
            "epoch: 10, iter: 300, loss: 0.061905289947893204\n",
            "epoch: 10, iter: 350, loss: 0.08756635081209159\n",
            "epoch: 10, iter: 400, loss: 0.11190252812253626\n",
            "epoch: 10, iter: 450, loss: 0.05910925572936557\n",
            "Epoch 10 completed. Accuracy: 97.74% \n",
            "\n",
            "epoch: 11, iter: 0, loss: 0.03528688599707592\n",
            "epoch: 11, iter: 50, loss: 0.07477313754556009\n",
            "epoch: 11, iter: 100, loss: 0.028453553656252125\n",
            "epoch: 11, iter: 150, loss: 0.03883819470180002\n",
            "epoch: 11, iter: 200, loss: 0.04650199304280009\n",
            "epoch: 11, iter: 250, loss: 0.05648481229510588\n",
            "epoch: 11, iter: 300, loss: 0.04660421789776232\n",
            "epoch: 11, iter: 350, loss: 0.07130003573117664\n",
            "epoch: 11, iter: 400, loss: 0.09561312003205784\n",
            "epoch: 11, iter: 450, loss: 0.04661254635129387\n",
            "Epoch 11 completed. Accuracy: 97.84% \n",
            "\n",
            "epoch: 12, iter: 0, loss: 0.04139932920574678\n",
            "epoch: 12, iter: 50, loss: 0.05017641045386129\n",
            "epoch: 12, iter: 100, loss: 0.0384168991194794\n",
            "epoch: 12, iter: 150, loss: 0.04098232296043032\n",
            "epoch: 12, iter: 200, loss: 0.033679591460468845\n",
            "epoch: 12, iter: 250, loss: 0.04891912441987047\n",
            "epoch: 12, iter: 300, loss: 0.059129550011115556\n",
            "epoch: 12, iter: 350, loss: 0.06224709098306476\n",
            "epoch: 12, iter: 400, loss: 0.08781763054775901\n",
            "epoch: 12, iter: 450, loss: 0.08875394802598612\n",
            "Epoch 12 completed. Accuracy: 97.84% \n",
            "\n",
            "epoch: 13, iter: 0, loss: 0.03418406966319387\n",
            "epoch: 13, iter: 50, loss: 0.031099919867491242\n",
            "epoch: 13, iter: 100, loss: 0.046151540643782456\n",
            "epoch: 13, iter: 150, loss: 0.03278126231321801\n",
            "epoch: 13, iter: 200, loss: 0.05298757637990945\n",
            "epoch: 13, iter: 250, loss: 0.02008412680104175\n",
            "epoch: 13, iter: 300, loss: 0.03861806603981362\n",
            "epoch: 13, iter: 350, loss: 0.03470974289334941\n",
            "epoch: 13, iter: 400, loss: 0.0782746211193675\n",
            "epoch: 13, iter: 450, loss: 0.04230284596337466\n",
            "Epoch 13 completed. Accuracy: 97.75% \n",
            "\n",
            "epoch: 14, iter: 0, loss: 0.035628234255361095\n",
            "epoch: 14, iter: 50, loss: 0.027883154359425684\n",
            "epoch: 14, iter: 100, loss: 0.037381257350206434\n",
            "epoch: 14, iter: 150, loss: 0.03187128693304204\n",
            "epoch: 14, iter: 200, loss: 0.04165537301814346\n",
            "epoch: 14, iter: 250, loss: 0.03015690254945383\n",
            "epoch: 14, iter: 300, loss: 0.02678021690372515\n",
            "epoch: 14, iter: 350, loss: 0.03319822672291279\n",
            "epoch: 14, iter: 400, loss: 0.08519629115495808\n",
            "epoch: 14, iter: 450, loss: 0.03080621461934622\n",
            "Epoch 14 completed. Accuracy: 97.71% \n",
            "\n",
            "epoch: 15, iter: 0, loss: 0.024032591549439437\n",
            "epoch: 15, iter: 50, loss: 0.062023533950372745\n",
            "epoch: 15, iter: 100, loss: 0.03292255134321625\n",
            "epoch: 15, iter: 150, loss: 0.027747140538106427\n",
            "epoch: 15, iter: 200, loss: 0.009718410636832684\n",
            "epoch: 15, iter: 250, loss: 0.029636706989764346\n",
            "epoch: 15, iter: 300, loss: 0.01901991328865391\n",
            "epoch: 15, iter: 350, loss: 0.025281968836213697\n",
            "epoch: 15, iter: 400, loss: 0.09408646017414847\n",
            "epoch: 15, iter: 450, loss: 0.023284017477343315\n",
            "Epoch 15 completed. Accuracy: 97.75% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8jiypNd94vPm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "16153e85-af6e-4025-a608-f3a8e4874476"
      },
      "source": [
        "mlp.save()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving model...\n",
            "Successfully saved model in MLP.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}