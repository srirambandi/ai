{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "mlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/ai/blob/master/examples/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQW0qqp740HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LibCB-XB4vOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-O0VSL4vOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file):\n",
        "    dict = np.load(file, allow_pickle=True)\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEYH3ZN14vO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = 'MNIST/train.npy'\n",
        "test_file = 'MNIST/test.npy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIzkJJya51pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2rQwaU54vO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(ai.Module):\n",
        "    def __init__(self, ):\n",
        "        self.fc1 = ai.Linear(784, 200)\n",
        "        self.fc2 = ai.Linear(200, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        o1 = ai.G.dropout(ai.G.relu(self.fc1.forward(x)), p=0.75)\n",
        "        o2 = ai.G.softmax(self.fc2.forward(o1))\n",
        "        return o2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pQFl-Bu4vPF",
        "colab_type": "code",
        "outputId": "ca50abcc-cd1a-4b26-94e2-7824ce22b550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "mlp = MLP()\n",
        "print(mlp)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  fc1: Linear(input_features=784, output_features=200, bias=True)\n",
            "  fc2: Linear(input_features=200, output_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "und8_6p34vPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = ai.Loss(loss_fn='CrossEntropyLoss')\n",
        "optim = ai.Optimizer(mlp.parameters(), optim_fn='Adam', lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc5mvajn4vPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dict = load_data(train_file)\n",
        "inputs = train_dict.item()['data']\n",
        "outputs = train_dict.item()['labels']\n",
        "del train_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtCUv7Fp4vPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0LW735v4vPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate():\n",
        "    ai.G.grad_mode = False\n",
        "    file = test_file\n",
        "    dict = load_data(file)\n",
        "    inputs = dict.item()['data']\n",
        "    outputs = dict.item()['labels']\n",
        "    correct, total = 0, 0\n",
        "    test_m = m\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "        input = inputs[batch * test_m : (batch + 1) * test_m] / 255\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = np.array(outputs[batch * test_m : (batch + 1) * test_m])\n",
        "        scores = mlp.forward(input)\n",
        "        preds = np.argmax(scores.data, axis=0)\n",
        "        correct += np.sum(np.equal(output, preds))\n",
        "        total += test_m\n",
        "    accuracy = float(correct / total)\n",
        "    ai.G.grad_mode = True\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iZl6HCB4vPi",
        "colab_type": "code",
        "outputId": "be404c1c-0657-40c2-c222-efdb760b1be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "while epoch < 15:\n",
        "    epoch += 1\n",
        "    it = 0\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "    # for batch in range(1):\n",
        "        input = inputs[batch * m : (batch + 1) * m] / 255\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = outputs[batch * m : (batch + 1) * m]\n",
        "        onehot = np.zeros((10, m))\n",
        "        for _ in range(m):\n",
        "            onehot[output[_], _] = 1.0\n",
        "        scores = mlp.forward(input)\n",
        "        loss = L.loss(scores, onehot)\n",
        "        loss.backward()\n",
        "        optim.step()        # update parameters with optimization functions\n",
        "        optim.zero_grad()   # clearing the backprop list and resetting the gradients to zero\n",
        "        if it%50 == 0:\n",
        "            print('epoch: {}, iter: {}, loss: {}'.format(epoch, it, loss.data[0, 0]))\n",
        "        it += 1\n",
        "    print('Epoch {} completed. Accuracy: {:.2%} \\n'.format(epoch, evaluate()))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Adam\n",
            "epoch: 1, iter: 0, loss: 2.3029468194362273\n",
            "epoch: 1, iter: 50, loss: 0.744773933515146\n",
            "epoch: 1, iter: 100, loss: 0.4461368333963829\n",
            "epoch: 1, iter: 150, loss: 0.3924592712027108\n",
            "epoch: 1, iter: 200, loss: 0.3276155178169168\n",
            "epoch: 1, iter: 250, loss: 0.34157984271946407\n",
            "epoch: 1, iter: 300, loss: 0.27599564051208175\n",
            "epoch: 1, iter: 350, loss: 0.42015027652099113\n",
            "epoch: 1, iter: 400, loss: 0.332420048816242\n",
            "epoch: 1, iter: 450, loss: 0.32262224911312576\n",
            "Epoch 1 completed. Accuracy: 92.83% \n",
            "\n",
            "epoch: 2, iter: 0, loss: 0.22569922187600583\n",
            "epoch: 2, iter: 50, loss: 0.23741324849821216\n",
            "epoch: 2, iter: 100, loss: 0.16844311398976142\n",
            "epoch: 2, iter: 150, loss: 0.21456708947819647\n",
            "epoch: 2, iter: 200, loss: 0.17467302930789977\n",
            "epoch: 2, iter: 250, loss: 0.2273470363272249\n",
            "epoch: 2, iter: 300, loss: 0.1835680741701417\n",
            "epoch: 2, iter: 350, loss: 0.3081284886653894\n",
            "epoch: 2, iter: 400, loss: 0.22054432726155443\n",
            "epoch: 2, iter: 450, loss: 0.2531417764028556\n",
            "Epoch 2 completed. Accuracy: 95.09% \n",
            "\n",
            "epoch: 3, iter: 0, loss: 0.13457880514971776\n",
            "epoch: 3, iter: 50, loss: 0.14709488406596885\n",
            "epoch: 3, iter: 100, loss: 0.11742375260612976\n",
            "epoch: 3, iter: 150, loss: 0.13703007823029337\n",
            "epoch: 3, iter: 200, loss: 0.14996722855430303\n",
            "epoch: 3, iter: 250, loss: 0.168505714676284\n",
            "epoch: 3, iter: 300, loss: 0.14941781627598216\n",
            "epoch: 3, iter: 350, loss: 0.2550077277896635\n",
            "epoch: 3, iter: 400, loss: 0.17812819963903073\n",
            "epoch: 3, iter: 450, loss: 0.17629039263584542\n",
            "Epoch 3 completed. Accuracy: 95.93% \n",
            "\n",
            "epoch: 4, iter: 0, loss: 0.08900014732230352\n",
            "epoch: 4, iter: 50, loss: 0.1553918497521911\n",
            "epoch: 4, iter: 100, loss: 0.0857496911700461\n",
            "epoch: 4, iter: 150, loss: 0.11655058008873176\n",
            "epoch: 4, iter: 200, loss: 0.15517484452624725\n",
            "epoch: 4, iter: 250, loss: 0.17614489999376637\n",
            "epoch: 4, iter: 300, loss: 0.11697274378622685\n",
            "epoch: 4, iter: 350, loss: 0.22336413540035407\n",
            "epoch: 4, iter: 400, loss: 0.1708022628270599\n",
            "epoch: 4, iter: 450, loss: 0.1516091925979817\n",
            "Epoch 4 completed. Accuracy: 96.67% \n",
            "\n",
            "epoch: 5, iter: 0, loss: 0.08673625660777781\n",
            "epoch: 5, iter: 50, loss: 0.10130812284279418\n",
            "epoch: 5, iter: 100, loss: 0.0788128112637949\n",
            "epoch: 5, iter: 150, loss: 0.07782391947482004\n",
            "epoch: 5, iter: 200, loss: 0.12886934624030558\n",
            "epoch: 5, iter: 250, loss: 0.11774999620316869\n",
            "epoch: 5, iter: 300, loss: 0.09165161543127731\n",
            "epoch: 5, iter: 350, loss: 0.19139898090297727\n",
            "epoch: 5, iter: 400, loss: 0.13946762676963742\n",
            "epoch: 5, iter: 450, loss: 0.1326873663328159\n",
            "Epoch 5 completed. Accuracy: 97.10% \n",
            "\n",
            "epoch: 6, iter: 0, loss: 0.08534964984052301\n",
            "epoch: 6, iter: 50, loss: 0.11883366730375224\n",
            "epoch: 6, iter: 100, loss: 0.051751741191736825\n",
            "epoch: 6, iter: 150, loss: 0.06069082014205247\n",
            "epoch: 6, iter: 200, loss: 0.11621551923482554\n",
            "epoch: 6, iter: 250, loss: 0.10562480096867839\n",
            "epoch: 6, iter: 300, loss: 0.07274133883347116\n",
            "epoch: 6, iter: 350, loss: 0.12857535022367197\n",
            "epoch: 6, iter: 400, loss: 0.11503565484615183\n",
            "epoch: 6, iter: 450, loss: 0.11262824812208251\n",
            "Epoch 6 completed. Accuracy: 97.16% \n",
            "\n",
            "epoch: 7, iter: 0, loss: 0.06862394439082142\n",
            "epoch: 7, iter: 50, loss: 0.07254621778669118\n",
            "epoch: 7, iter: 100, loss: 0.05766896498602085\n",
            "epoch: 7, iter: 150, loss: 0.07915495057430107\n",
            "epoch: 7, iter: 200, loss: 0.10877000340441523\n",
            "epoch: 7, iter: 250, loss: 0.10207995661819932\n",
            "epoch: 7, iter: 300, loss: 0.0716630444618966\n",
            "epoch: 7, iter: 350, loss: 0.12531045115679756\n",
            "epoch: 7, iter: 400, loss: 0.09775168605241977\n",
            "epoch: 7, iter: 450, loss: 0.09504924653944166\n",
            "Epoch 7 completed. Accuracy: 97.51% \n",
            "\n",
            "epoch: 8, iter: 0, loss: 0.05422180939953599\n",
            "epoch: 8, iter: 50, loss: 0.06841524615025281\n",
            "epoch: 8, iter: 100, loss: 0.031550529541573766\n",
            "epoch: 8, iter: 150, loss: 0.08835127560020067\n",
            "epoch: 8, iter: 200, loss: 0.07031217046853816\n",
            "epoch: 8, iter: 250, loss: 0.06970591164760931\n",
            "epoch: 8, iter: 300, loss: 0.0453827670361507\n",
            "epoch: 8, iter: 350, loss: 0.11376554122733398\n",
            "epoch: 8, iter: 400, loss: 0.10386499946675001\n",
            "epoch: 8, iter: 450, loss: 0.08641988756153887\n",
            "Epoch 8 completed. Accuracy: 97.57% \n",
            "\n",
            "epoch: 9, iter: 0, loss: 0.08171707616828178\n",
            "epoch: 9, iter: 50, loss: 0.04779106956591192\n",
            "epoch: 9, iter: 100, loss: 0.06009713389469871\n",
            "epoch: 9, iter: 150, loss: 0.0547161641233252\n",
            "epoch: 9, iter: 200, loss: 0.07658934114098402\n",
            "epoch: 9, iter: 250, loss: 0.05339389169648734\n",
            "epoch: 9, iter: 300, loss: 0.034092301048855876\n",
            "epoch: 9, iter: 350, loss: 0.08353401043611564\n",
            "epoch: 9, iter: 400, loss: 0.1023783607244227\n",
            "epoch: 9, iter: 450, loss: 0.07696580864185423\n",
            "Epoch 9 completed. Accuracy: 97.71% \n",
            "\n",
            "epoch: 10, iter: 0, loss: 0.06573063964430279\n",
            "epoch: 10, iter: 50, loss: 0.05343939466749267\n",
            "epoch: 10, iter: 100, loss: 0.02504792208017656\n",
            "epoch: 10, iter: 150, loss: 0.025171595577513615\n",
            "epoch: 10, iter: 200, loss: 0.05173888735258672\n",
            "epoch: 10, iter: 250, loss: 0.0404919593261055\n",
            "epoch: 10, iter: 300, loss: 0.06027346878110014\n",
            "epoch: 10, iter: 350, loss: 0.08086935735873291\n",
            "epoch: 10, iter: 400, loss: 0.11636201940259977\n",
            "epoch: 10, iter: 450, loss: 0.03561136095847622\n",
            "Epoch 10 completed. Accuracy: 97.81% \n",
            "\n",
            "epoch: 11, iter: 0, loss: 0.08181692569794785\n",
            "epoch: 11, iter: 50, loss: 0.0691836337754142\n",
            "epoch: 11, iter: 100, loss: 0.03410813772510883\n",
            "epoch: 11, iter: 150, loss: 0.037118124863497484\n",
            "epoch: 11, iter: 200, loss: 0.03542681463253383\n",
            "epoch: 11, iter: 250, loss: 0.048949548050909605\n",
            "epoch: 11, iter: 300, loss: 0.039644690527797066\n",
            "epoch: 11, iter: 350, loss: 0.04160106468959568\n",
            "epoch: 11, iter: 400, loss: 0.0962060464842523\n",
            "epoch: 11, iter: 450, loss: 0.08328904700452285\n",
            "Epoch 11 completed. Accuracy: 97.83% \n",
            "\n",
            "epoch: 12, iter: 0, loss: 0.03400378844875879\n",
            "epoch: 12, iter: 50, loss: 0.047197738480810436\n",
            "epoch: 12, iter: 100, loss: 0.05627216693263769\n",
            "epoch: 12, iter: 150, loss: 0.02172809371568298\n",
            "epoch: 12, iter: 200, loss: 0.05502801899122208\n",
            "epoch: 12, iter: 250, loss: 0.07118793781482968\n",
            "epoch: 12, iter: 300, loss: 0.05319700904619414\n",
            "epoch: 12, iter: 350, loss: 0.044534624826409394\n",
            "epoch: 12, iter: 400, loss: 0.0958071123142341\n",
            "epoch: 12, iter: 450, loss: 0.035578413584269726\n",
            "Epoch 12 completed. Accuracy: 97.90% \n",
            "\n",
            "epoch: 13, iter: 0, loss: 0.030644068333815333\n",
            "epoch: 13, iter: 50, loss: 0.024688473689187907\n",
            "epoch: 13, iter: 100, loss: 0.02407249049905065\n",
            "epoch: 13, iter: 150, loss: 0.019446971236776796\n",
            "epoch: 13, iter: 200, loss: 0.05068096684431721\n",
            "epoch: 13, iter: 250, loss: 0.021258050797614753\n",
            "epoch: 13, iter: 300, loss: 0.04144264441445832\n",
            "epoch: 13, iter: 350, loss: 0.041643358582094864\n",
            "epoch: 13, iter: 400, loss: 0.10800715086689235\n",
            "epoch: 13, iter: 450, loss: 0.040581243039035625\n",
            "Epoch 13 completed. Accuracy: 97.97% \n",
            "\n",
            "epoch: 14, iter: 0, loss: 0.03133673145102358\n",
            "epoch: 14, iter: 50, loss: 0.030251700825308408\n",
            "epoch: 14, iter: 100, loss: 0.027691259410572065\n",
            "epoch: 14, iter: 150, loss: 0.047088971501650416\n",
            "epoch: 14, iter: 200, loss: 0.02761961986260586\n",
            "epoch: 14, iter: 250, loss: 0.048196460963099465\n",
            "epoch: 14, iter: 300, loss: 0.03507893855750612\n",
            "epoch: 14, iter: 350, loss: 0.050442095714917604\n",
            "epoch: 14, iter: 400, loss: 0.06865350535162533\n",
            "epoch: 14, iter: 450, loss: 0.03529913536676329\n",
            "Epoch 14 completed. Accuracy: 98.00% \n",
            "\n",
            "epoch: 15, iter: 0, loss: 0.032120385253579464\n",
            "epoch: 15, iter: 50, loss: 0.026718617579355914\n",
            "epoch: 15, iter: 100, loss: 0.02017142532704469\n",
            "epoch: 15, iter: 150, loss: 0.034001170329842\n",
            "epoch: 15, iter: 200, loss: 0.05725124001293663\n",
            "epoch: 15, iter: 250, loss: 0.03149889602862656\n",
            "epoch: 15, iter: 300, loss: 0.02017825276880995\n",
            "epoch: 15, iter: 350, loss: 0.05300908421821116\n",
            "epoch: 15, iter: 400, loss: 0.09331344874514744\n",
            "epoch: 15, iter: 450, loss: 0.03316962262215541\n",
            "Epoch 15 completed. Accuracy: 97.91% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jiypNd94vPm",
        "colab_type": "code",
        "outputId": "91126c91-03af-4be4-dd83-877a542e7c70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "mlp.save()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving model...\n",
            "Successfully saved model in MLP.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}