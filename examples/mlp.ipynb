{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "mlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirambandi/ai/blob/master/examples/mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQW0qqp740HL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# when running in colab notebooks, first install library\n",
        "!pip install import-ai\n",
        "# upload respective dataset manually from examples directory of the library or download as below\n",
        "!apt install subversion\n",
        "!svn checkout https://github.com/srirambandi/ai/trunk/examples/MNIST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LibCB-XB4vOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ai\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QB-O0VSL4vOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(file):\n",
        "    dict = np.load(file, allow_pickle=True)\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEYH3ZN14vO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_file = 'MNIST/train.npy'\n",
        "test_file = 'MNIST/test.npy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIzkJJya51pQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ai.manual_seed(2357)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2rQwaU54vO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(ai.Module):\n",
        "    def __init__(self, ):\n",
        "        self.fc1 = ai.Linear(784, 200)\n",
        "        self.fc2 = ai.Linear(200, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        o1 = ai.G.dropout(ai.G.relu(self.fc1.forward(x)), p=0.75)\n",
        "        o2 = ai.G.softmax(self.fc2.forward(o1))\n",
        "        return o2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pQFl-Bu4vPF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "64f7fd4e-11d6-423d-c43b-9d59f55905a5"
      },
      "source": [
        "mlp = MLP()\n",
        "print(mlp)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MLP(\n",
            "  fc1: Linear(input_features=784, output_features=200, bias=True)\n",
            "  fc2: Linear(input_features=200, output_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "und8_6p34vPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "L = ai.Loss(loss_fn='CrossEntropyLoss')\n",
        "optim = ai.Optimizer(mlp.parameters(), optim_fn='Adam', lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc5mvajn4vPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dict = load_data(train_file)\n",
        "inputs = train_dict.item()['data']\n",
        "outputs = train_dict.item()['labels']\n",
        "del train_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtCUv7Fp4vPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "it, epoch = 0, 0\n",
        "m = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0LW735v4vPe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate():\n",
        "    ai.G.grad_mode = False\n",
        "    file = test_file\n",
        "    dict = load_data(file)\n",
        "    inputs = dict.item()['data']\n",
        "    outputs = dict.item()['labels']\n",
        "    correct, total = 0, 0\n",
        "    test_m = m\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "        input = inputs[batch * test_m : (batch + 1) * test_m] / 255\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = np.array(outputs[batch * test_m : (batch + 1) * test_m])\n",
        "        scores = mlp.forward(input)\n",
        "        preds = np.argmax(scores.data, axis=0)\n",
        "        correct += np.sum(np.equal(output, preds))\n",
        "        total += test_m\n",
        "    accuracy = float(correct / total)\n",
        "    ai.G.grad_mode = True\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iZl6HCB4vPi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "214816e8-b9d7-43d4-b8f5-aa5cb5736dc6"
      },
      "source": [
        "while epoch < 5:\n",
        "    epoch += 1\n",
        "    it = 0\n",
        "    for batch in range(int(len(outputs) / m)):\n",
        "    # for batch in range(1):\n",
        "        input = inputs[batch * m : (batch + 1) * m] / 255\n",
        "        input =  np.stack([_ for _ in input], axis = -1)\n",
        "        output = outputs[batch * m : (batch + 1) * m]\n",
        "        onehot = np.zeros((10, m))\n",
        "        for _ in range(m):\n",
        "            onehot[output[_], _] = 1.0\n",
        "        scores = mlp.forward(input)\n",
        "        loss = L.loss(scores, onehot)\n",
        "        loss.backward()\n",
        "        optim.step()        # update parameters with optimization functions\n",
        "        optim.zero_grad()   # clearing the backprop list and resetting the gradients to zero\n",
        "        if it%200 == 0:\n",
        "            print('epoch: {}, iter: {}, loss: {}'.format(epoch, it, loss.data[0, 0]))\n",
        "        it += 1\n",
        "    print('Epoch {} completed. Accuracy: {:.2%} \\n'.format(epoch, evaluate()))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Adam\n",
            "epoch: 1, iter: 0, loss: 2.3024607699888233\n",
            "epoch: 1, iter: 200, loss: 0.5509934782016774\n",
            "epoch: 1, iter: 400, loss: 0.1963255241342034\n",
            "epoch: 1, iter: 600, loss: 0.19324132610302003\n",
            "epoch: 1, iter: 800, loss: 0.14940603683515608\n",
            "epoch: 1, iter: 1000, loss: 0.46653691946253023\n",
            "epoch: 1, iter: 1200, loss: 0.23489468012700013\n",
            "epoch: 1, iter: 1400, loss: 0.34028662540882726\n",
            "epoch: 1, iter: 1600, loss: 0.32505392339834516\n",
            "epoch: 1, iter: 1800, loss: 0.22487526142855124\n",
            "Epoch 1 completed. Accuracy: 94.59% \n",
            "\n",
            "epoch: 2, iter: 0, loss: 0.18658965386633153\n",
            "epoch: 2, iter: 200, loss: 0.28932866500514975\n",
            "epoch: 2, iter: 400, loss: 0.1033409666111588\n",
            "epoch: 2, iter: 600, loss: 0.0822160421772012\n",
            "epoch: 2, iter: 800, loss: 0.16944196835060607\n",
            "epoch: 2, iter: 1000, loss: 0.27251367589645015\n",
            "epoch: 2, iter: 1200, loss: 0.16349470733601326\n",
            "epoch: 2, iter: 1400, loss: 0.17660167434360982\n",
            "epoch: 2, iter: 1600, loss: 0.23917613692219092\n",
            "epoch: 2, iter: 1800, loss: 0.17952662284694282\n",
            "Epoch 2 completed. Accuracy: 96.00% \n",
            "\n",
            "epoch: 3, iter: 0, loss: 0.11160934711502371\n",
            "epoch: 3, iter: 200, loss: 0.20098266959821498\n",
            "epoch: 3, iter: 400, loss: 0.13063121033046415\n",
            "epoch: 3, iter: 600, loss: 0.08216616041250292\n",
            "epoch: 3, iter: 800, loss: 0.05963983414375904\n",
            "epoch: 3, iter: 1000, loss: 0.13604894410545132\n",
            "epoch: 3, iter: 1200, loss: 0.0761481735587307\n",
            "epoch: 3, iter: 1400, loss: 0.10970033952687486\n",
            "epoch: 3, iter: 1600, loss: 0.1366469725332578\n",
            "epoch: 3, iter: 1800, loss: 0.19929232371441996\n",
            "Epoch 3 completed. Accuracy: 96.89% \n",
            "\n",
            "epoch: 4, iter: 0, loss: 0.05376495672074405\n",
            "epoch: 4, iter: 200, loss: 0.21805954297018743\n",
            "epoch: 4, iter: 400, loss: 0.1101574705386269\n",
            "epoch: 4, iter: 600, loss: 0.07622544922956588\n",
            "epoch: 4, iter: 800, loss: 0.08019296575277872\n",
            "epoch: 4, iter: 1000, loss: 0.12052659889787931\n",
            "epoch: 4, iter: 1200, loss: 0.11115998539638246\n",
            "epoch: 4, iter: 1400, loss: 0.06516919603065932\n",
            "epoch: 4, iter: 1600, loss: 0.057751715907281696\n",
            "epoch: 4, iter: 1800, loss: 0.10477222922244309\n",
            "Epoch 4 completed. Accuracy: 97.60% \n",
            "\n",
            "epoch: 5, iter: 0, loss: 0.03398401202883737\n",
            "epoch: 5, iter: 200, loss: 0.04676218850779101\n",
            "epoch: 5, iter: 400, loss: 0.09376003997867075\n",
            "epoch: 5, iter: 600, loss: 0.03042346093866301\n",
            "epoch: 5, iter: 800, loss: 0.05399609195991627\n",
            "epoch: 5, iter: 1000, loss: 0.16385729910188485\n",
            "epoch: 5, iter: 1200, loss: 0.040501310951462956\n",
            "epoch: 5, iter: 1400, loss: 0.05694798651625805\n",
            "epoch: 5, iter: 1600, loss: 0.08518973460423337\n",
            "epoch: 5, iter: 1800, loss: 0.11646524779184717\n",
            "Epoch 5 completed. Accuracy: 97.40% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jiypNd94vPm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d60b387f-5332-4604-b43e-7898f932209b"
      },
      "source": [
        "mlp.save()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saving model...\n",
            "Successfully saved model in MLP.npy\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}