{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import ai\n", "import numpy as np"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_data(file):\n", "    dict = np.load(file, allow_pickle=True)\n", "    return dict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_file = 'MNIST/train.npy'\n", "test_file = 'MNIST/test.npy'"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class MLP(ai.Model):\n", "    def __init__(self, ):\n", "        self.fc1 = ai.Linear(784, 200)\n", "        self.fc2 = ai.Linear(200, 10)\n", "    def forward(self, x):\n", "        o1 = ai.G.dropout(ai.G.relu(self.fc1.forward(x)), p=0.75)\n", "        o2 = ai.G.softmax(self.fc2.forward(o1))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["        return o2"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mlp = MLP()\n", "print(mlp)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["L = ai.Loss(loss_fn='CrossEntropyLoss')\n", "optim = ai.Optimizer(mlp.parameters(), optim_fn='Adam', lr=1e-3)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["train_dict = load_data(train_file)\n", "inputs = train_dict.item()['data']\n", "outputs = train_dict.item()['labels']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["del train_dict"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["it, epoch = 0, 0\n", "m = 32"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def evaluate():\n", "    ai.G.grad_mode = False\n", "    file = test_file\n", "    dict = load_data(file)\n", "    inputs = dict.item()['data']\n", "    outputs = dict.item()['labels']\n", "    correct, total = 0, 0\n", "    test_m = m\n", "    for batch in range(int(len(outputs) / m)):\n", "        input = inputs[batch * test_m : (batch + 1) * test_m] / 255\n", "        input =  np.stack([_ for _ in input], axis = -1)\n", "        output = np.array(outputs[batch * test_m : (batch + 1) * test_m])\n", "        scores = mlp.forward(input)\n", "        preds = np.argmax(scores.data, axis=0)\n", "        correct += np.sum(np.equal(output, preds))\n", "        total += test_m\n", "    accuracy = float(correct / total)\n", "    ai.G.grad_mode = True\n", "    return accuracy"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["while epoch < 10:\n", "    epoch += 1\n", "    it = 0\n", "    for batch in range(int(len(outputs) / m)):\n", "    # for batch in range(1):\n", "        input = inputs[batch * m : (batch + 1) * m] / 255\n", "        input =  np.stack([_ for _ in input], axis = -1)\n", "        output = outputs[batch * m : (batch + 1) * m]\n", "        onehot = np.zeros((10, m))\n", "        for _ in range(m):\n", "            onehot[output[_], _] = 1.0\n", "        scores = mlp.forward(input)\n", "        loss = L.loss(scores, onehot)\n", "        loss.backward()\n", "        optim.step()        # update parameters with optimization functions\n", "        optim.zero_grad()   # clearing the backprop list and resetting the gradients to zero\n", "        if it%10 == 0:\n", "            print('epoch: {}, iter: {}, loss: {}'.format(epoch, it, loss.data[0, 0]))\n", "        it += 1\n", "    print('\\n\\n', 'Epoch {} completed. Accuracy: {}'.format(epoch, evaluate()))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["mlp.save()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}